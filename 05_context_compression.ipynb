{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬5ç« ï¼šä¸Šä¸‹æ–‡å‹ç¼© - 8æ®µå¼å‹ç¼©ç®—æ³•\n",
    "\n",
    "## æœ¬ç« ç›®æ ‡\n",
    "\n",
    "æœ¬ç« å°†å®ç°ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿï¼Œè®©Agentèƒ½å¤Ÿåœ¨é•¿å¯¹è¯ä¸­è‡ªåŠ¨å‹ç¼©å†å²æ¶ˆæ¯ï¼Œä¿æŒä¸Šä¸‹æ–‡çª—å£åœ¨å®‰å…¨èŒƒå›´å†…ã€‚ä½ å°†å­¦ä¹ ï¼š\n",
    "\n",
    "- **Tokenç›‘æ§æœºåˆ¶**: å®æ—¶è¿½è¸ªtokenä½¿ç”¨æƒ…å†µ\n",
    "- **æ™ºèƒ½å‹ç¼©é˜ˆå€¼**: 92%é˜ˆå€¼è‡ªåŠ¨è§¦å‘å‹ç¼©\n",
    "- **8æ®µå¼å‹ç¼©ç­–ç•¥**: å°†å¯¹è¯å†å²æŒ‰é‡è¦æ€§åˆ†æ®µå‹ç¼©\n",
    "- **å‹ç¼©èŠ‚ç‚¹è®¾è®¡**: åœ¨å›¾ä¸­æ·»åŠ ä¸“é—¨çš„å‹ç¼©å¤„ç†èŠ‚ç‚¹\n",
    "- **æ¶ˆæ¯ä¿ç•™ç­–ç•¥**: ä¿ç•™æœ€è¿‘æ¶ˆæ¯ + å‹ç¼©æ‘˜è¦\n",
    "- **å€’åºæŸ¥æ‰¾ä¼˜åŒ–**: ä»O(n)ä¼˜åŒ–åˆ°O(k)çš„æŸ¥æ‰¾æ•ˆç‡\n",
    "\n",
    "## åº”ç”¨åœºæ™¯\n",
    "\n",
    "- **é•¿ä¼šè¯å¯¹è¯**: å¤šè½®å¤æ‚å¯¹è¯ä¸ä¼šè¶…å‡ºä¸Šä¸‹æ–‡é™åˆ¶\n",
    "- **é¡¹ç›®å¼€å‘åŠ©æ‰‹**: ä¿æŒæ•´ä¸ªå¼€å‘è¿‡ç¨‹çš„ä¸Šä¸‹æ–‡\n",
    "- **çŸ¥è¯†åº“é—®ç­”**: é•¿æ–‡æ¡£åˆ†æå’Œå¤šæ¬¡æŸ¥è¯¢\n",
    "- **æ•™å­¦è¾…å¯¼**: æŒç»­çš„å­¦ä¹ å¯¹è¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ è¿™æ˜¯ Claude Code çš„ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ\n",
    "\n",
    "è¿™æ˜¯ Claude Code çš„**é•¿å¯¹è¯è®°å¿†ç®¡ç†**ã€‚å½“ä½ å’Œå®ƒèŠäº†å¾ˆä¹…ï¼Œå¯¹è¯å†å²å ç”¨äº†å¤§é‡ token æ—¶ï¼š\n",
    "\n",
    "**æ²¡æœ‰å‹ç¼©**ï¼š\n",
    "- å¯¹è¯è¶Šæ¥è¶Šæ…¢ï¼ˆAPI è°ƒç”¨è€—æ—¶å¢åŠ ï¼‰\n",
    "- æœ€ç»ˆè¾¾åˆ° token ä¸Šé™ï¼Œå¯¹è¯ä¸­æ–­\n",
    "- æˆæœ¬è¶Šæ¥è¶Šé«˜\n",
    "\n",
    "**æœ‰å‹ç¼©ï¼ˆClaude Code çš„åšæ³•ï¼‰**ï¼š\n",
    "- åœ¨ token è¾¾åˆ° 92% æ—¶è‡ªåŠ¨è§¦å‘\n",
    "- ç”¨ LLM å°†å†å²å¯¹è¯å‹ç¼©æˆç®€æ´æ‘˜è¦\n",
    "- ä¿ç•™æœ€è¿‘çš„å‡ æ¡åŸå§‹æ¶ˆæ¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡è¿è´¯ï¼‰\n",
    "- ç”¨æˆ·æ— æ„ŸçŸ¥ï¼Œå¯¹è¯ç»§ç»­æµç•…è¿›è¡Œ\n",
    "\n",
    "**æŠ€æœ¯è¦ç‚¹**ï¼š\n",
    "- å€’åºæŸ¥æ‰¾ token usageï¼ˆä» O(n) ä¼˜åŒ–åˆ° O(k)ï¼‰\n",
    "- 8 æ®µå¼å‹ç¼©ç­–ç•¥ï¼ˆè¯¦ç»†æ•è·æŠ€æœ¯ç»†èŠ‚ã€ä»£ç æ¨¡å¼ã€æ¶æ„å†³ç­–ï¼‰\n",
    "- 92% é˜ˆå€¼è§¦å‘ï¼ˆç»è¿‡ A/B æµ‹è¯•ä¼˜åŒ–ï¼‰\n",
    "\n",
    "æœ¬ç« å®ç°çš„å‹ç¼©ç­–ç•¥ï¼Œå°±æ˜¯ Claude Code çš„å®é™…ç”Ÿäº§æ–¹æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import TypedDict, List, Optional, Annotated\n",
    "from datetime import datetime\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition, create_react_agent\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, \n",
    "    SystemMessage, \n",
    "    AIMessage, \n",
    "    BaseMessage,\n",
    "    RemoveMessage\n",
    ")\n",
    "\n",
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"chapter-05-context-compression\"\n",
    "\n",
    "# åˆå§‹åŒ–LLM\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0)\n",
    "\n",
    "# é€‰é¡¹2: é€šä¹‰åƒé—® (å–æ¶ˆæ³¨é‡Šä½¿ç”¨)\n",
    "# llm = ChatTongyi(model=\"qwen-max\", temperature=0)\n",
    "print(f\"âœ… LLMåˆå§‹åŒ–æˆåŠŸ: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenç›‘æ§æœºåˆ¶\n",
    "\n",
    "### æ ¸å¿ƒè®¾è®¡ç‰¹ç‚¹\n",
    "\n",
    "1. **å€’åºéå†ä¼˜åŒ–**: ä»æœ€æ–°æ¶ˆæ¯å¾€å‰æ‰¾ï¼Œæ—¶é—´å¤æ‚åº¦ä»O(n)é™åˆ°O(k)\n",
    "2. **ç²¾ç¡®Tokenè®¡ç®—**: æ¶µç›–inputã€cache_creationã€cache_readã€outputå››ç±»Token\n",
    "3. **æ¨¡å‹å…¼å®¹**: æ”¯æŒOpenAIå’ŒClaudeçš„tokenç»Ÿè®¡æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_token_usage(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"å€’åºæŸ¥æ‰¾æœ€æ–°çš„tokenä½¿ç”¨æƒ…å†µ\n",
    "    \n",
    "    è¿™æ˜¯ä¸€ä¸ªä¼˜åŒ–çš„å®ç°ï¼Œé¿å…éå†æ‰€æœ‰æ¶ˆæ¯ã€‚\n",
    "    ä»æœ€æ–°çš„æ¶ˆæ¯å¼€å§‹æŸ¥æ‰¾ï¼Œå› ä¸ºtoken usageä¿¡æ¯é€šå¸¸åœ¨æœ€è¿‘çš„AIMessageä¸­ã€‚\n",
    "    \n",
    "    Args:\n",
    "        messages: æ¶ˆæ¯åˆ—è¡¨\n",
    "        \n",
    "    Returns:\n",
    "        æœ€æ–°çš„tokenä½¿ç”¨æ€»æ•°\n",
    "    \"\"\"\n",
    "    # å€’åºæ‰«æï¼Œæ‰¾åˆ°æœ€æ–°çš„usageä¿¡æ¯\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, AIMessage) and hasattr(msg, 'response_metadata'): # æ³¨æ„ï¼šä¸åŒçš„LLM APIè¿”å›çš„tokenç»Ÿè®¡æ ¼å¼å¯èƒ½ä¸åŒã€‚\n",
    "            usage = msg.response_metadata.get('token_usage', {})\n",
    "            \n",
    "            if usage:\n",
    "                # ç²¾ç¡®è®¡ç®—ï¼šåŒ…å«æ‰€æœ‰tokenç±»å‹\n",
    "                total = usage.get('total_tokens', 0)\n",
    "                if total > 0:\n",
    "                    return total\n",
    "    \n",
    "    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°usageä¿¡æ¯ï¼Œè¿”å›0\n",
    "    return 0\n",
    "\n",
    "\n",
    "def estimate_tokens(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"ä¼°ç®—tokenæ•°é‡ï¼ˆå½“æ²¡æœ‰ç²¾ç¡®token_usageæ—¶ä½¿ç”¨ï¼‰\n",
    "    \n",
    "    ç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4 ä¸ªå­—ç¬¦ï¼ˆè‹±æ–‡ï¼‰æˆ– 1.5 ä¸ªå­—ç¬¦ï¼ˆä¸­æ–‡ï¼‰\n",
    "    \n",
    "    Args:\n",
    "        messages: æ¶ˆæ¯åˆ—è¡¨\n",
    "        \n",
    "    Returns:\n",
    "        ä¼°ç®—çš„tokenæ€»æ•°\n",
    "    \"\"\"\n",
    "    total_chars = 0\n",
    "    \n",
    "    for msg in messages:\n",
    "        if hasattr(msg, 'content') and msg.content:\n",
    "            total_chars += len(str(msg.content))\n",
    "    \n",
    "    # ä½¿ç”¨ä¿å®ˆä¼°ç®—ï¼ˆå‡è®¾ä¸­è‹±æ–‡æ··åˆï¼‰\n",
    "    return int(total_chars / 3)\n",
    "\n",
    "\n",
    "print(\"âœ… Tokenç›‘æ§å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ä¸ºä»€ä¹ˆå€’åºæŸ¥æ‰¾æœ€åä¸€æ¡AIäº§ç”Ÿçš„messageï¼Ÿ**  \n",
    "å› ä¸ºè¿™æ¡messageä¸­åŒ…å«total_tokens, æ˜¯æˆªæ­¢åˆ°è¿™æ¡messageï¼Œ LLMçœ‹åˆ°çš„å’Œç”Ÿæˆçš„æ‰€æœ‰messageåŒ…å«çš„tokenæ€»æ•°ï¼Œå³ä¸Šä¸‹æ–‡é•¿åº¦ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å‹ç¼©åˆ¤æ–­é€»è¾‘\n",
    "\n",
    "### 92%é˜ˆå€¼çš„è€ƒé‡\n",
    "\n",
    "- **ä¸ºä»€ä¹ˆæ˜¯92%ï¼Ÿ** ç»è¿‡A/Bæµ‹è¯•ä¼˜åŒ–çš„æœ€ä½³å‹ç¼©ç‚¹\n",
    "- **é¢„ç•™ç©ºé—´**: ä¸ºæ¨¡å‹è¾“å‡ºé¢„ç•™è¶³å¤Ÿçš„tokenç©ºé—´\n",
    "- **å¹³è¡¡ä½“éªŒ**: é¿å…é¢‘ç¹å‹ç¼©ï¼ŒåŒæ—¶é˜²æ­¢è¶…å‡ºé™åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_THRESHOLD = 0.92\n",
    "\n",
    "def needs_compression(\n",
    "    messages: List[BaseMessage],\n",
    "    max_tokens: int = 128000,  # Claude Sonnet 3.5ä¸Šä¸‹æ–‡çª—å£\n",
    "    reserved_output: int = 4000 # ä¸ºè¾“å‡ºé¢„ç•™çš„token\n",
    ") -> bool:\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©\n",
    "    \n",
    "    ç»¼åˆè€ƒè™‘ï¼š\n",
    "    1. å½“å‰tokenä½¿ç”¨é‡\n",
    "    2. æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£å¤§å°\n",
    "    3. é¢„ç•™çš„è¾“å‡ºç©ºé—´\n",
    "    \n",
    "    Args:\n",
    "        messages: æ¶ˆæ¯åˆ—è¡¨\n",
    "        max_tokens: æœ€å¤§tokenæ•°\n",
    "        reserved_output: ä¸ºè¾“å‡ºé¢„ç•™çš„tokenæ•°\n",
    "        \n",
    "    Returns:\n",
    "        æ˜¯å¦éœ€è¦å‹ç¼©\n",
    "    \"\"\"\n",
    "    threshold = TOKEN_THRESHOLD\n",
    "    # è·å–å½“å‰tokenä½¿ç”¨é‡\n",
    "    current_tokens = get_latest_token_usage(messages)\n",
    "    \n",
    "    # å¦‚æœæ²¡æœ‰ç²¾ç¡®çš„usageä¿¡æ¯ï¼Œä½¿ç”¨ä¼°ç®—\n",
    "    if current_tokens == 0:\n",
    "        current_tokens = estimate_tokens(messages)\n",
    "    \n",
    "    # è®¡ç®—å¯ç”¨tokenï¼ˆå‡å»é¢„ç•™çš„è¾“å‡ºç©ºé—´ï¼‰\n",
    "    available_tokens = max_tokens - reserved_output\n",
    "    \n",
    "    # è®¡ç®—ä½¿ç”¨ç‡\n",
    "    usage_ratio = current_tokens / available_tokens\n",
    "    \n",
    "    print(f\"ğŸ“Š Tokenä½¿ç”¨æƒ…å†µ:\")\n",
    "    print(f\"   å½“å‰: {current_tokens:,} tokens\")\n",
    "    print(f\"   å¯ç”¨: {available_tokens:,} tokens\")\n",
    "    print(f\"   ä½¿ç”¨ç‡: {usage_ratio:.1%}\")\n",
    "    print(f\"   é˜ˆå€¼: {threshold:.1%}\")\n",
    "    \n",
    "    return usage_ratio > threshold\n",
    "\n",
    "\n",
    "print(\"âœ… å‹ç¼©åˆ¤æ–­å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 8æ®µå¼å‹ç¼©æç¤ºè¯\n",
    "\n",
    "è¿™æ˜¯claude-codeçš„æ ¸å¿ƒå‹ç¼©ç­–ç•¥ï¼Œå°†å¯¹è¯å†å²åˆ†ä¸º9ä¸ªå…³é”®éƒ¨åˆ†è¿›è¡Œç»“æ„åŒ–å‹ç¼©ã€‚\n",
    "\n",
    "### è®¾è®¡æ€æƒ³\n",
    "\n",
    "1. **ç»“æ„åŒ–**: ç¡®ä¿é‡è¦ä¿¡æ¯ä¸ä¸¢å¤±\n",
    "2. **å…¨é¢æ€§**: è¦†ç›–æ‰€æœ‰å…³é”®ç»´åº¦\n",
    "3. **å¯æ¢å¤**: åç»­å¯¹è¯èƒ½åŸºäºæ‘˜è¦ç»§ç»­\n",
    "4. **è´¨é‡ä¿è¯**: ä½¿ç”¨`<analysis>`æ ‡ç­¾å¼ºåˆ¶æ€è€ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8æ®µå¼å‹ç¼©æç¤ºè¯ï¼ˆå®Œæ•´ç‰ˆï¼‰\n",
    "COMPRESSION_PROMPT = \"\"\"ä½ çš„ä»»åŠ¡æ˜¯åˆ›å»ºåˆ°ç›®å‰ä¸ºæ­¢å¯¹è¯çš„è¯¦ç»†æ‘˜è¦ï¼Œå¯†åˆ‡å…³æ³¨ç”¨æˆ·çš„æ˜ç¡®è¯·æ±‚å’Œä½ ä¹‹å‰çš„è¡ŒåŠ¨ã€‚\n",
    "æ­¤æ‘˜è¦åº”å½»åº•æ•è·æŠ€æœ¯ç»†èŠ‚ã€ä»£ç æ¨¡å¼å’Œæ¶æ„å†³ç­–ï¼Œè¿™äº›å¯¹äºåœ¨ä¸ä¸¢å¤±ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ç»§ç»­å¼€å‘å·¥ä½œè‡³å…³é‡è¦ã€‚\n",
    "\n",
    "åœ¨æä¾›æœ€ç»ˆæ‘˜è¦ä¹‹å‰ï¼Œå°†ä½ çš„åˆ†æåŒ…è£…åœ¨<analysis>æ ‡ç­¾ä¸­ï¼Œä»¥ç»„ç»‡ä½ çš„æ€è€ƒå¹¶ç¡®ä¿ä½ æ¶µç›–äº†æ‰€æœ‰å¿…è¦çš„è¦ç‚¹ã€‚\n",
    "\n",
    "ä½ çš„æ‘˜è¦åº”åŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†:\n",
    "\n",
    "1. **ä¸»è¦è¯·æ±‚å’Œæ„å›¾**: è¯¦ç»†æ•è·ç”¨æˆ·çš„æ‰€æœ‰æ˜ç¡®è¯·æ±‚å’Œæ„å›¾\n",
    "   - ç”¨æˆ·æ˜ç¡®è¯´äº†ä»€ä¹ˆï¼Ÿ\n",
    "   - ä»»åŠ¡çš„æ ¸å¿ƒç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "   - æœ‰å“ªäº›éšå«çš„éœ€æ±‚ï¼Ÿ\n",
    "\n",
    "2. **å…³é”®æŠ€æœ¯æ¦‚å¿µ**: åˆ—å‡ºè®¨è®ºçš„æ‰€æœ‰é‡è¦æŠ€æœ¯æ¦‚å¿µã€æŠ€æœ¯å’Œæ¡†æ¶\n",
    "   - ä½¿ç”¨äº†å“ªäº›æŠ€æœ¯æ ˆï¼Ÿ\n",
    "   - æ¶‰åŠå“ªäº›æ ¸å¿ƒæ¦‚å¿µï¼Ÿ\n",
    "   - æœ‰å“ªäº›é‡è¦çš„æ¶æ„å†³ç­–ï¼Ÿ\n",
    "\n",
    "3. **æ–‡ä»¶å’Œä»£ç æ®µ**: æšä¸¾æ£€æŸ¥ã€ä¿®æ”¹æˆ–åˆ›å»ºçš„ç‰¹å®šæ–‡ä»¶å’Œä»£ç æ®µ\n",
    "   - ç‰¹åˆ«æ³¨æ„æœ€è¿‘çš„æ¶ˆæ¯\n",
    "   - åŒ…å«å®Œæ•´çš„ä»£ç ç‰‡æ®µï¼ˆå¦‚é€‚ç”¨ï¼‰\n",
    "   - è®°å½•æ–‡ä»¶è·¯å¾„å’Œå…³é”®è¡Œå·\n",
    "\n",
    "4. **é”™è¯¯å’Œä¿®å¤**: åˆ—å‡ºä½ é‡åˆ°çš„æ‰€æœ‰é”™è¯¯ä»¥åŠä¿®å¤æ–¹æ³•\n",
    "   - å…·ä½“çš„é”™è¯¯ä¿¡æ¯\n",
    "   - è§£å†³æ–¹æ¡ˆå’ŒåŸå› \n",
    "   - ç‰¹åˆ«æ³¨æ„ç”¨æˆ·çš„åé¦ˆ\n",
    "\n",
    "5. **é—®é¢˜è§£å†³**: è®°å½•å·²è§£å†³çš„é—®é¢˜å’Œä»»ä½•æ­£åœ¨è¿›è¡Œçš„æ•…éšœæ’é™¤å·¥ä½œ\n",
    "   - è§£å†³äº†å“ªäº›éš¾é¢˜ï¼Ÿ\n",
    "   - é‡‡ç”¨äº†ä»€ä¹ˆæ–¹æ³•ï¼Ÿ\n",
    "   - è¿˜æœ‰å“ªäº›æœªè§£å†³çš„é—®é¢˜ï¼Ÿ\n",
    "\n",
    "6. **æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯**: åˆ—å‡ºæ‰€æœ‰éå·¥å…·ç»“æœçš„ç”¨æˆ·æ¶ˆæ¯\n",
    "   - è¿™äº›å¯¹äºç†è§£ç”¨æˆ·çš„åé¦ˆå’Œå˜åŒ–çš„æ„å›¾è‡³å…³é‡è¦\n",
    "   - æŒ‰æ—¶é—´é¡ºåºåˆ—å‡º\n",
    "   - æ³¨æ„ç”¨æˆ·æ€åº¦å’Œéœ€æ±‚çš„å˜åŒ–\n",
    "\n",
    "7. **å¾…å¤„ç†ä»»åŠ¡**: æ¦‚è¿°ä½ æ˜ç¡®è¢«è¦æ±‚å¤„ç†çš„ä»»ä½•å¾…å¤„ç†ä»»åŠ¡\n",
    "   - å“ªäº›ä»»åŠ¡è¿˜æ²¡å®Œæˆï¼Ÿ\n",
    "   - ä¼˜å…ˆçº§å¦‚ä½•ï¼Ÿ\n",
    "   - æœ‰å“ªäº›ä¾èµ–å…³ç³»ï¼Ÿ\n",
    "\n",
    "8. **å½“å‰å·¥ä½œ**: è¯¦ç»†æè¿°åœ¨æ­¤æ‘˜è¦è¯·æ±‚ä¹‹å‰æ­£åœ¨è¿›è¡Œçš„ç¡®åˆ‡å·¥ä½œ\n",
    "   - æœ€ååœ¨åšä»€ä¹ˆï¼Ÿ\n",
    "   - è¿›å±•åˆ°å“ªä¸€æ­¥äº†ï¼Ÿ\n",
    "   - ä¸‹ä¸€æ­¥è®¡åˆ’åšä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "9. **å¯é€‰çš„ä¸‹ä¸€æ­¥**: åˆ—å‡ºä¸ä½ æœ€è¿‘æ­£åœ¨åšçš„å·¥ä½œç›¸å…³çš„ä¸‹ä¸€æ­¥\n",
    "   - é€»è¾‘ä¸Šçš„ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "   - æœ‰å“ªäº›å¯èƒ½çš„æ–¹å‘ï¼Ÿ\n",
    "\n",
    "è¯·ç¡®ä¿æ‘˜è¦è¶³å¤Ÿè¯¦ç»†ï¼Œä½¿å¾—å¦ä¸€ä¸ªAIåŠ©æ‰‹ï¼ˆæˆ–ä½ è‡ªå·±åœ¨æ–°ä¼šè¯ä¸­ï¼‰èƒ½å¤Ÿæ— ç¼åœ°ç»§ç»­è¿™ä¸ªå¯¹è¯å’Œå·¥ä½œã€‚\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… 8æ®µå¼å‹ç¼©æç¤ºè¯å®šä¹‰å®Œæˆ\")\n",
    "print(f\"æç¤ºè¯é•¿åº¦: {len(COMPRESSION_PROMPT)} å­—ç¬¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å‹ç¼©èŠ‚ç‚¹å®ç°\n",
    "\n",
    "å‹ç¼©èŠ‚ç‚¹çš„æ ¸å¿ƒèŒè´£ï¼š\n",
    "1. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©\n",
    "2. è°ƒç”¨LLMç”Ÿæˆ8æ®µå¼æ‘˜è¦\n",
    "3. ä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯\n",
    "4. å°†æ‘˜è¦æ’å…¥æ¶ˆæ¯å†å²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from typing import TypedDict\n",
    "\n",
    "class CompressionRecord(TypedDict):\n",
    "    \"\"\"å‹ç¼©è®°å½•\"\"\"\n",
    "    timestamp: str\n",
    "    messages_removed: int\n",
    "    messages_kept: int\n",
    "    tokens_before: int\n",
    "    tokens_after: int\n",
    "    summary_content: str\n",
    "    \n",
    "\n",
    "def compression_node(state: dict) -> dict:\n",
    "    \"\"\"ä¸Šä¸‹æ–‡å‹ç¼©èŠ‚ç‚¹\n",
    "    \n",
    "    å·¥ä½œæµç¨‹ï¼š\n",
    "    1. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©\n",
    "    2. å¦‚æœä¸éœ€è¦ï¼Œç›´æ¥è¿”å›ç©ºå­—å…¸\n",
    "    3. å¦‚æœéœ€è¦ï¼Œè°ƒç”¨LLMç”Ÿæˆæ‘˜è¦\n",
    "    4. åˆ é™¤æ—§æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘æ¶ˆæ¯å’Œæ‘˜è¦\n",
    "    5. è®°å½•å‹ç¼©å†å²åˆ°compression_history\n",
    "    \n",
    "    Args:\n",
    "        state: å½“å‰çŠ¶æ€\n",
    "        \n",
    "    Returns:\n",
    "        æ›´æ–°åçš„çŠ¶æ€ï¼ˆmessageså­—æ®µå’Œcompression_historyå­—æ®µï¼‰\n",
    "    \"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ—œï¸  å‹ç¼©èŠ‚ç‚¹æ‰§è¡Œ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©\n",
    "    if not needs_compression(messages):\n",
    "        print(\"âœ… Tokenä½¿ç”¨ç‡åœ¨å®‰å…¨èŒƒå›´å†…ï¼Œæ— éœ€å‹ç¼©\")\n",
    "        return {}\n",
    "    \n",
    "    print(\"âš ï¸  Tokenä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼ï¼Œå¼€å§‹å‹ç¼©...\")\n",
    "    \n",
    "    # è®°å½•å‹ç¼©å‰çš„tokenæ•°é‡\n",
    "    tokens_before = get_latest_token_usage(messages)\n",
    "    if tokens_before == 0:\n",
    "        tokens_before = estimate_tokens(messages)\n",
    "    \n",
    "    # 2. è°ƒç”¨LLMç”Ÿæˆå‹ç¼©æ‘˜è¦\n",
    "    try:\n",
    "        print(\"ğŸ“ ç”Ÿæˆ8æ®µå¼å‹ç¼©æ‘˜è¦...\")\n",
    "        \n",
    "        # æ„å»ºå‹ç¼©è¯·æ±‚\n",
    "        compression_messages = [\n",
    "            SystemMessage(content=COMPRESSION_PROMPT),\n",
    "            *messages  # åŒ…å«å®Œæ•´å¯¹è¯å†å²\n",
    "        ]\n",
    "        \n",
    "        # è°ƒç”¨LLM\n",
    "        summary_response = llm.invoke(compression_messages)\n",
    "        summary_content = summary_response.content\n",
    "\n",
    "        print(\"=\"*60)\n",
    "        print(f\"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(summary_content)} å­—ç¬¦ï¼Œå†…å®¹å¦‚ä¸‹ï¼š\")\n",
    "        print(\"=\"*60)\n",
    "        print(summary_content)\n",
    "        \n",
    "        # 3. å†³å®šä¿ç•™å¤šå°‘æœ€è¿‘æ¶ˆæ¯\n",
    "        # ç­–ç•¥ï¼šä¿ç•™æœ€è¿‘3æ¡æ¶ˆæ¯\n",
    "        keep_recent = 3\n",
    "        \n",
    "        if len(messages) <= keep_recent:\n",
    "            print(\"âš ï¸  æ¶ˆæ¯æ•°é‡è¾ƒå°‘ï¼Œä¸è¿›è¡Œå‹ç¼©\")\n",
    "            return {}\n",
    "        \n",
    "        # 4. æ„å»ºæ–°çš„æ¶ˆæ¯åˆ—è¡¨\n",
    "        # åˆ é™¤æ—§æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯\n",
    "        messages_to_remove = messages[:-keep_recent]\n",
    "        recent_messages = messages[-keep_recent:]\n",
    "        \n",
    "        # å¦‚æœæ‹†åˆ†ç‚¹ä¸‹ä¸€æ¡æ˜¯ToolMessage, å°†è¯¥æ¡messageä¹Ÿåˆ é™¤\n",
    "        if recent_messages and isinstance(recent_messages[0], ToolMessage):\n",
    "            messages_to_remove.append(recent_messages[0])\n",
    "            recent_messages = recent_messages[1:]\n",
    "        \n",
    "        # åˆ›å»ºæ‘˜è¦æ¶ˆæ¯\n",
    "        summary_message = AIMessage(\n",
    "            content=f\"\"\"ğŸ“‹ **å¯¹è¯æ‘˜è¦** (å‹ç¼©äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n",
    "\n",
    "{summary_content}\n",
    "\n",
    "---\n",
    "*ä»¥ä¸Šæ˜¯ä¹‹å‰ {len(messages_to_remove)} æ¡æ¶ˆæ¯çš„æ‘˜è¦ï¼Œä»¥ä¸‹æ˜¯æœ€è¿‘çš„å¯¹è¯*\n",
    "\"\"\"\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ—‘ï¸  åˆ é™¤æ—§æ¶ˆæ¯: {len(messages_to_remove)} æ¡\")\n",
    "        print(f\"ğŸ“Œ ä¿ç•™æœ€è¿‘æ¶ˆæ¯: {len(recent_messages)} æ¡\")\n",
    "        print(f\"ğŸ“„ æ·»åŠ æ‘˜è¦: 1 æ¡\")\n",
    "        \n",
    "        # 5. è¿”å›æ›´æ–°\n",
    "        # ä½¿ç”¨RemoveMessageåˆ é™¤æ—§æ¶ˆæ¯\n",
    "        remove_messages = [RemoveMessage(id=msg.id) for msg in messages_to_remove if hasattr(msg, 'id')]\n",
    "        \n",
    "        # è®¡ç®—å‹ç¼©åçš„tokenæ•°é‡\n",
    "        new_messages_for_count = recent_messages + [summary_message]\n",
    "        tokens_after = estimate_tokens(new_messages_for_count)\n",
    "        \n",
    "        # 6. åˆ›å»ºå‹ç¼©è®°å½•\n",
    "        compression_record: CompressionRecord = {\n",
    "            \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"messages_removed\": len(messages_to_remove),\n",
    "            \"messages_kept\": len(recent_messages),\n",
    "            \"tokens_before\": tokens_before,\n",
    "            \"tokens_after\": tokens_after,\n",
    "            \"summary_content\": summary_content[:200] + \"...\" if len(summary_content) > 200 else summary_content\n",
    "        }\n",
    "        \n",
    "        # 7. è·å–ç°æœ‰çš„å‹ç¼©å†å²å¹¶æ·»åŠ æ–°è®°å½•\n",
    "        compression_history = state.get(\"compression_history\", [])\n",
    "        \n",
    "        print(f\"ğŸ“Š å‹ç¼©ç»Ÿè®¡:\")\n",
    "        print(f\"   å‹ç¼©å‰: {tokens_before:,} tokens\")\n",
    "        print(f\"   å‹ç¼©å: {tokens_after:,} tokens\")\n",
    "        print(f\"   èŠ‚çœ: {tokens_before - tokens_after:,} tokens ({(tokens_before - tokens_after) / tokens_before * 100:.1f}%)\")\n",
    "        \n",
    "        # è¿”å›æ›´æ–°çš„å®Œæ•´åˆ—è¡¨\n",
    "        return {\n",
    "            \"messages\": remove_messages + [summary_message],\n",
    "            \"compression_history\": compression_history + [compression_record]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å‹ç¼©å¤±è´¥: {e}\")\n",
    "        print(\"ç»§ç»­æ‰§è¡Œï¼Œä¸è¿›è¡Œå‹ç¼©\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "print(\"âœ… å‹ç¼©èŠ‚ç‚¹å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ä¸Šé¢ä»£ç éœ€è¦æ³¨æ„çš„æ˜¯ï¼š**\n",
    "1. compression_nodeæ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ƒè¿”å›çš„messagesé€šè¿‡add_message Reduceræ›´æ–°state[\"messages\"]\n",
    "\n",
    "2. RemoveMessage ä¸»è¦ç”¨äºåœ¨ä½¿ç”¨ add_messages Reducer æ—¶ï¼Œé€šè¿‡æ¶ˆæ¯ ID åˆ é™¤ç‰¹å®šæ¶ˆæ¯ã€‚\n",
    "\n",
    "```python\n",
    "    from langchain_core.messages import RemoveMessage\n",
    "\n",
    "    # å‡è®¾ä½ æœ‰ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«äº†å·¥å…·è°ƒç”¨å’Œç»“æœ\n",
    "    messages = [\n",
    "        HumanMessage(\"å¸®æˆ‘æŸ¥å¤©æ°”\", id=\"1\"),\n",
    "        AIMessage(\"æ­£åœ¨æŸ¥è¯¢...\", id=\"2\", tool_calls=[...]),\n",
    "        ToolMessage(\"åŒ—äº¬ä»Šå¤©æ™´å¤©\", id=\"3\", tool_call_id=\"call-123\"),\n",
    "        AIMessage(\"åŒ—äº¬ä»Šå¤©æ™´å¤©\", id=\"4\")\n",
    "    ]\n",
    "\n",
    "    # åˆ é™¤ä¸­é—´çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆid=\"3\"ï¼‰\n",
    "    state[\"messages\"] = add_messages(\n",
    "        state[\"messages\"],\n",
    "        [RemoveMessage(id=\"3\")]  # ğŸ‘ˆ åˆ é™¤æŒ‡å®šIDçš„æ¶ˆæ¯\n",
    "    )\n",
    "```\n",
    "3. messages[:-keep_recent]å¯èƒ½ä¼šéš”æ–­å¸¦tool_callsçš„AIMessageså’Œå¯¹åº”çš„ToolMessageï¼Œä¼šå¯¼è‡´æŠ¥é”™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ‰©å±•Stateå®šä¹‰ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯ä»¥æ·»åŠ compression_historyæ¥è¿½è¸ªå‹ç¼©æ“ä½œã€‚\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"æ‰©å±•çš„AgentçŠ¶æ€\n",
    "    \n",
    "    åŒ…å«ï¼š\n",
    "    - messages: å¯¹è¯å†å²\n",
    "    - compression_history: å‹ç¼©å†å²ï¼ˆå¯é€‰ï¼‰\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    compression_history: List[CompressionRecord]  # ä¸éœ€è¦ reducerï¼Œç›´æ¥æ›¿æ¢\n",
    "\n",
    "\n",
    "print(\"âœ… Stateå®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 å‹ç¼©å†å²è¾…åŠ©å‡½æ•°\n",
    "\n",
    "è¿™äº›å‡½æ•°å¸®åŠ©ä½ æ›´å¥½åœ°ç®¡ç†å’ŒæŸ¥è¯¢å‹ç¼©å†å²ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ„å»ºå¸¦å‹ç¼©åŠŸèƒ½çš„Agent\n",
    "\n",
    "æˆ‘ä»¬å°†åœ¨æ ‡å‡†ReAct Agentçš„åŸºç¡€ä¸Šæ·»åŠ å‹ç¼©èŠ‚ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸€äº›æµ‹è¯•å·¥å…·\n",
    "@tool\n",
    "def search_docs(query: str) -> str:\n",
    "    \"\"\"æœç´¢æ–‡æ¡£ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "    \n",
    "    Args:\n",
    "        query: æœç´¢å…³é”®è¯\n",
    "    \"\"\"\n",
    "    return f\"æ‰¾åˆ°å…³äº'{query}'çš„æ–‡æ¡£ï¼š\\n1. æ–‡æ¡£A - è¿™æ˜¯ä¸€ç¯‡å…³äº{query}çš„è¯¦ç»†ä»‹ç»...\\n2. æ–‡æ¡£B - {query}çš„æœ€ä½³å®è·µ...\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def analyze_code(code: str) -> str:\n",
    "    \"\"\"åˆ†æä»£ç ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "    \n",
    "    Args:\n",
    "        code: è¦åˆ†æçš„ä»£ç \n",
    "    \"\"\"\n",
    "    return f\"ä»£ç åˆ†æç»“æœï¼š\\n- ä»£ç è¡Œæ•°: {len(code.split())}\\n- å¤æ‚åº¦: ä¸­ç­‰\\n- å»ºè®®: å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–...\"\n",
    "\n",
    "\n",
    "tools = [search_docs, analyze_code]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# å®šä¹‰agentèŠ‚ç‚¹\n",
    "def agent_node(state: AgentState):\n",
    "    \"\"\"AgentèŠ‚ç‚¹ï¼šè°ƒç”¨LLM\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # æ·»åŠ ç³»ç»Ÿæç¤º\n",
    "    system_msg = SystemMessage(\n",
    "        content=\"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æœç´¢æ–‡æ¡£å’Œåˆ†æä»£ç ã€‚è¯·å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚\"\n",
    "    )\n",
    "    \n",
    "    response = llm_with_tools.invoke([system_msg] + messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# å®šä¹‰å·¥å…·èŠ‚ç‚¹\n",
    "def tool_node(state: AgentState):\n",
    "    \"\"\"å·¥å…·èŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…·\"\"\"\n",
    "    from langchain_core.messages import ToolMessage\n",
    "    \n",
    "    tools_by_name = {t.name: t for t in tools}\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    results = []\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_func = tools_by_name[tool_call[\"name\"]]\n",
    "        result = tool_func.invoke(tool_call[\"args\"])\n",
    "        results.append(ToolMessage(\n",
    "            content=str(result),\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        ))\n",
    "    \n",
    "    return {\"messages\": results}\n",
    "\n",
    "\n",
    "# æ¡ä»¶åˆ¤æ–­å‡½æ•°\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦ç»§ç»­\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "print(\"âœ… èŠ‚ç‚¹å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå›¾\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "builder.add_node(\"compression\", compression_node)  # æ–°å¢ï¼šå‹ç¼©èŠ‚ç‚¹\n",
    "builder.add_node(\"agent\", agent_node)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# æ·»åŠ è¾¹\n",
    "# å…³é”®ï¼šåœ¨agentå‰æ·»åŠ compressionæ£€æŸ¥\n",
    "builder.add_edge(START, \"compression\")\n",
    "builder.add_edge(\"compression\", \"agent\")\n",
    "\n",
    "# agentçš„æ¡ä»¶è¾¹\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# toolsæ‰§è¡Œåå›åˆ°compressionæ£€æŸ¥\n",
    "builder.add_edge(\"tools\", \"compression\")\n",
    "\n",
    "# ç¼–è¯‘\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"âœ… å›¾æ„å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å›¾ç»“æ„\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"æ— æ³•æ˜¾ç¤ºå›¾åƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æµ‹è¯•æ¡ˆä¾‹\n",
    "\n",
    "### æµ‹è¯•1ï¼šçŸ­å¯¹è¯ï¼ˆä¸è§¦å‘å‹ç¼©ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"æµ‹è¯•1ï¼šçŸ­å¯¹è¯ - ä¸åº”è§¦å‘å‹ç¼©\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"æœç´¢å…³äºLangGraphçš„æ–‡æ¡£\")],\n",
    "    \"compression_history\": []\n",
    "})\n",
    "\n",
    "print(\"\\næœ€ç»ˆå›ç­”:\")\n",
    "result[\"messages\"][-1].pretty_print()\n",
    "\n",
    "print(f\"\\næ¶ˆæ¯æ€»æ•°: {len(result['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•2ï¼šæ¨¡æ‹Ÿé•¿å¯¹è¯ï¼ˆè§¦å‘å‹ç¼©ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"æµ‹è¯•2ï¼šé•¿å¯¹è¯æ¨¡æ‹Ÿ - åº”è§¦å‘å‹ç¼©\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æˆ‘ä»¬é€šè¿‡é™ä½é˜ˆå€¼æ¥æ¨¡æ‹Ÿè§¦å‘å‹ç¼©çš„åœºæ™¯ã€‚\n",
    "TOKEN_THRESHOLD = 0.01\n",
    "\n",
    "# æ¨¡æ‹Ÿä¸€ä¸ªé•¿å¯¹è¯\n",
    "long_conversation = []\n",
    "\n",
    "# æ·»åŠ å¤šè½®å¯¹è¯\n",
    "questions = [\n",
    "    \"æœç´¢LangGraphçš„åŸºç¡€æ¦‚å¿µ\",\n",
    "    \"åˆ†æä»¥ä¸‹ä»£ç ï¼šdef hello(): pass\",\n",
    "    \"æœç´¢StateGraphçš„ç”¨æ³•\",\n",
    "    \"æœç´¢ToolNodeçš„å®ç°\",\n",
    "    \"æœç´¢MessagesStateçš„å®šä¹‰\",\n",
    "    \"æœç´¢æ¡ä»¶è¾¹çš„ä½¿ç”¨\",\n",
    "    \"æœç´¢interruptæœºåˆ¶\",\n",
    "    \"æœç´¢checkpointerçš„é…ç½®\"\n",
    "]\n",
    "\n",
    "state = {\"messages\": [], \"compression_history\": []}\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ç¬¬ {i} è½®å¯¹è¯: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    state[\"messages\"].append(HumanMessage(content=question))\n",
    "    \n",
    "    # æ‰§è¡Œ\n",
    "    result = graph.invoke(state)\n",
    "    state = result\n",
    "    \n",
    "    print(f\"\\nå½“å‰æ¶ˆæ¯æ•°: {len(state['messages'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é•¿å¯¹è¯æµ‹è¯•å®Œæˆ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æœ€ç»ˆæ¶ˆæ¯æ•°: {len(state['messages'])}\")\n",
    "\n",
    "# æ˜¾ç¤ºæœ€åå‡ æ¡æ¶ˆæ¯\n",
    "print(\"\\næœ€å3æ¡æ¶ˆæ¯:\")\n",
    "for i, msg in enumerate(state['messages'][-3:], 1):\n",
    "    print(f\"\\n[{i}] {msg.__class__.__name__}:\")\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(content[:200] + \"...\" if len(content) > 200 else content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹å‹ç¼©å†å²\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š å‹ç¼©å†å²ç»Ÿè®¡\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "compression_history = state.get(\"compression_history\", [])\n",
    "\n",
    "if not compression_history:\n",
    "    print(\"âŒ æ²¡æœ‰å‹ç¼©è®°å½•\")\n",
    "else:\n",
    "    print(f\"\\næ€»å‹ç¼©æ¬¡æ•°: {len(compression_history)}\\n\")\n",
    "    \n",
    "    for i, record in enumerate(compression_history, 1):\n",
    "        print(f\"ç¬¬ {i} æ¬¡å‹ç¼©:\")\n",
    "        print(f\"  æ—¶é—´: {record['timestamp']}\")\n",
    "        print(f\"  åˆ é™¤æ¶ˆæ¯: {record['messages_removed']} æ¡\")\n",
    "        print(f\"  ä¿ç•™æ¶ˆæ¯: {record['messages_kept']} æ¡\")\n",
    "        print(f\"  å‹ç¼©å‰: {record['tokens_before']:,} tokens\")\n",
    "        print(f\"  å‹ç¼©å: {record['tokens_after']:,} tokens\")\n",
    "        \n",
    "        saved_tokens = record['tokens_before'] - record['tokens_after']\n",
    "        saved_percent = (saved_tokens / record['tokens_before'] * 100) if record['tokens_before'] > 0 else 0\n",
    "        \n",
    "        print(f\"  èŠ‚çœ: {saved_tokens:,} tokens ({saved_percent:.1f}%)\")\n",
    "        print(f\"  æ‘˜è¦é¢„è§ˆ: {record['summary_content'][:100]}...\")\n",
    "        print()\n",
    "    \n",
    "    # ç»Ÿè®¡æ€»èŠ‚çœ\n",
    "    total_removed = sum(r['messages_removed'] for r in compression_history)\n",
    "    total_tokens_before = sum(r['tokens_before'] for r in compression_history)\n",
    "    total_tokens_after = sum(r['tokens_after'] for r in compression_history)\n",
    "    total_saved = total_tokens_before - total_tokens_after\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"æ€»è®¡:\")\n",
    "    print(f\"  æ€»åˆ é™¤æ¶ˆæ¯: {total_removed} æ¡\")\n",
    "    print(f\"  æ€»èŠ‚çœtokens: {total_saved:,} ({(total_saved / total_tokens_before * 100) if total_tokens_before > 0 else 0:.1f}%)\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ç»ƒä¹ é¢˜\n",
    "\n",
    "### ç»ƒä¹ 1: è‡ªé€‚åº”é˜ˆå€¼\n",
    "å®ç°åŠ¨æ€é˜ˆå€¼ï¼šæ ¹æ®å¯¹è¯è½®æ¬¡è‡ªåŠ¨è°ƒæ•´å‹ç¼©é˜ˆå€¼ã€‚\n",
    "\n",
    "### ç»ƒä¹ 2: åˆ†æ®µå‹ç¼©\n",
    "å°†æ¶ˆæ¯å†å²åˆ†æˆå¤šä¸ªæ—¶é—´æ®µï¼Œåˆ†åˆ«å‹ç¼©ï¼Œä¿ç•™æ—¶é—´çº¿ã€‚\n",
    "\n",
    "### ç»ƒä¹ 3: å‹ç¼©è´¨é‡è¯„ä¼°\n",
    "æ·»åŠ å‹ç¼©åçš„ä¿¡æ¯ä¸¢å¤±æ£€æµ‹ï¼Œå¦‚æœä¸¢å¤±è¿‡å¤šå…³é”®ä¿¡æ¯åˆ™å›é€€ã€‚\n",
    "\n",
    "### æ€è€ƒé¢˜\n",
    "1. ä¸ºä»€ä¹ˆè¦å€’åºæŸ¥æ‰¾token usageï¼Ÿ\n",
    "2. å¦‚æœå‹ç¼©åçš„æ‘˜è¦æœ¬èº«å¾ˆé•¿æ€ä¹ˆåŠï¼Ÿ\n",
    "3. åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¸åº”è¯¥å‹ç¼©ï¼Ÿ\n",
    "4. å¦‚ä½•å¹³è¡¡å‹ç¼©é¢‘ç‡å’Œä¿¡æ¯ä¿ç•™ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ç”Ÿäº§ç¯å¢ƒå»ºè®®\n",
    "\n",
    "### ç›‘æ§æŒ‡æ ‡\n",
    "\n",
    "```python\n",
    "# å…³é”®æŒ‡æ ‡\n",
    "- å¹³å‡å‹ç¼©è§¦å‘é¢‘ç‡\n",
    "- å‹ç¼©å‰åtokenå˜åŒ–\n",
    "- å‹ç¼©è€—æ—¶\n",
    "- ä¿¡æ¯ä¿ç•™ç‡\n",
    "```\n",
    "\n",
    "### ä¼˜åŒ–ç­–ç•¥\n",
    "\n",
    "1. **ç¼“å­˜å‹ç¼©ç»“æœ**: ç›¸åŒå¯¹è¯æ¨¡å¼å¯å¤ç”¨æ‘˜è¦\n",
    "2. **å¼‚æ­¥å‹ç¼©**: å‹ç¼©æ“ä½œä¸é˜»å¡ä¸»æµç¨‹\n",
    "3. **åˆ†çº§å‹ç¼©**: ä¸åŒé‡è¦æ€§çš„æ¶ˆæ¯é‡‡ç”¨ä¸åŒå‹ç¼©ç‡\n",
    "4. **å‹ç¼©å†å²**: è®°å½•æ¯æ¬¡å‹ç¼©çš„è¯¦ç»†ä¿¡æ¯\n",
    "\n",
    "### æ³¨æ„äº‹é¡¹\n",
    "\n",
    "- **ä¸è¦è¿‡æ—©å‹ç¼©**: çŸ­å¯¹è¯ä¸éœ€è¦å‹ç¼©\n",
    "- **ä¿ç•™å…³é”®æ¶ˆæ¯**: ç”¨æˆ·æœ€æ–°æŒ‡ä»¤ã€é”™è¯¯ä¿¡æ¯ç­‰\n",
    "- **å®šæœŸå®¡æŸ¥**: æ£€æŸ¥å‹ç¼©è´¨é‡ï¼Œè°ƒæ•´ç­–ç•¥\n",
    "- **é™çº§æ–¹æ¡ˆ**: å‹ç¼©å¤±è´¥æ—¶çš„å…œåº•å¤„ç†\n",
    "- **â—ï¸ä½¿ç”¨å¼ºå¤§çš„æ¨¡å‹**ï¼šæµ‹è¯•ç”¨qwen-max,qwen3-maxå’Œgpt-4o-miniéƒ½æ²¡èƒ½ç”Ÿæˆé¢„æœŸçš„å‹ç¼©ä¿¡æ¯ï¼Œä½†[gpt-5ç”Ÿæˆçš„å‹ç¼©ä¿¡æ¯](./compression_messages_by_gpt5.txt)ç¬¦åˆé¢„æœŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ä¸‹ä¸€æ­¥\n",
    "\n",
    "åœ¨ä¸‹ä¸€ç« ï¼ˆç¬¬6ç« ï¼‰ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ï¼š\n",
    "- stream()æ–¹æ³•çš„ä¸åŒæ¨¡å¼\n",
    "- å®æ—¶Tokenæµå¼è¾“å‡º\n",
    "- ä¸­æ–­ä¸æ¢å¤æœºåˆ¶\n",
    "- å®æ—¶å“åº”çš„ç”¨æˆ·ä½“éªŒä¼˜åŒ–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
