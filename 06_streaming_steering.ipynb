{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬6ç« ï¼šæµå¼è¾“å‡ºå’Œä¸­æ–­ - Streaming-steering\n",
    "\n",
    "## æœ¬ç« ç›®æ ‡\n",
    "\n",
    "æœ¬ç« å°†å®ç°æµå¼å“åº”æœºåˆ¶ï¼Œè®©Agentèƒ½å¤Ÿå®æ—¶è¾“å‡ºæ‰§è¡Œè¿‡ç¨‹ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚ä½ å°†å­¦ä¹ ï¼š\n",
    "\n",
    "- **ä¸‰ç§streamæ¨¡å¼**: values, updates, messages\n",
    "- **äº‹ä»¶çº§åˆ«æµå¼è¾“å‡º**: astream_events\n",
    "- **å®æ—¶Tokenæµå¼**: é€å­—æ˜¾ç¤ºLLMè¾“å‡º\n",
    "- **æµå¼è¿›åº¦è¿½è¸ª**: æ˜¾ç¤ºèŠ‚ç‚¹è½¬æ¢å’Œå·¥å…·è°ƒç”¨\n",
    "\n",
    "## åº”ç”¨åœºæ™¯\n",
    "\n",
    "- **å®æ—¶å¯¹è¯**: åƒChatGPTä¸€æ ·é€å­—æ˜¾ç¤ºå›ç­”\n",
    "- **é•¿ä»»åŠ¡è¿½è¸ª**: æ˜¾ç¤ºAgentæ‰§è¡Œè¿›åº¦\n",
    "- **è°ƒè¯•ä¸ç›‘æ§**: å®æ—¶æŸ¥çœ‹Agentå†…éƒ¨çŠ¶æ€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ è¿™æ˜¯ Claude Code çš„ä»€ä¹ˆåŠŸèƒ½ï¼Ÿ\n",
    "\n",
    "è¿™æ˜¯ Claude Code çš„**å®æ—¶å“åº”æ˜¾ç¤º**å’Œ**æ‰§è¡Œæ§åˆ¶**ã€‚ä½ ä¼šçœ‹åˆ°ï¼š\n",
    "- Token ä¸€ä¸ªä¸ªè¹¦å‡ºæ¥ï¼ˆåƒæ‰“å­—æœºæ•ˆæœï¼‰\n",
    "- ä»»åŠ¡çŠ¶æ€å®æ—¶æ›´æ–°ï¼ˆ\"æ­£åœ¨åˆ†æ...\" â†’ \"æ­£åœ¨å†™å…¥...\"ï¼‰\n",
    "- å¯ä»¥éšæ—¶ç‚¹å‡» **\"Stop\" æŒ‰é’®ä¸­æ–­æ‰§è¡Œ**\n",
    "\n",
    "**ä¸¤ä¸ªæ ¸å¿ƒèƒ½åŠ›**ï¼š\n",
    "\n",
    "**1. æµå¼è¾“å‡º**ï¼š\n",
    "- ä¸ç”¨ç­‰ 30 ç§’æ‰çœ‹åˆ°ç»“æœï¼Œè¾¹æ‰§è¡Œè¾¹æ˜¾ç¤º\n",
    "- ç”¨æˆ·çŸ¥é“ AI å½“å‰åœ¨åšä»€ä¹ˆï¼ˆä¸æ˜¯å¡ä½äº†ï¼‰\n",
    "\n",
    "**2. ç®€å•ä¸­æ–­**ï¼š\n",
    "- ç”¨æˆ·ç‚¹å‡»åœæ­¢æŒ‰é’® â†’ ç«‹å³åœæ­¢å½“å‰æ‰§è¡Œ\n",
    "- ä¸ä¿å­˜çŠ¶æ€ï¼Œä¸æ¢å¤ï¼ˆå’Œç¬¬ 2 ç« çš„ interrupt ä¸åŒï¼‰\n",
    "- å…¸å‹åœºæ™¯ï¼šå‘ç° AI æ–¹å‘é”™äº†ï¼Œç›´æ¥åœæ­¢é‡æ–°å¼€å§‹\n",
    "\n",
    "**æŠ€æœ¯è¦ç‚¹**ï¼š\n",
    "- ä½¿ç”¨ `astream_events` å®æ—¶è·å–æ‰§è¡Œäº‹ä»¶\n",
    "- é€šè¿‡åœæ­¢è¿­ä»£æ¥ä¸­æ–­ï¼ˆè€Œé `interrupt()`ï¼‰\n",
    "- ä¸‰ç§æµå¼æ¨¡å¼ï¼šmessages/updates/values\n",
    "\n",
    "**ä¸ç¬¬ 2 ç«  Human-in-the-Loop çš„åŒºåˆ«**ï¼š\n",
    "- ç¬¬ 2 ç« ï¼šAI ä¸»åŠ¨æš‚åœï¼Œç­‰å¾…ç”¨æˆ·å®¡æ‰¹ï¼Œå¯æ¢å¤\n",
    "- ç¬¬ 6 ç« ï¼šç”¨æˆ·ä¸»åŠ¨åœæ­¢ï¼Œç›´æ¥ç»ˆæ­¢ï¼Œä¸æ¢å¤\n",
    "\n",
    "æœ¬ç« å®ç°çš„æµå¼æ¶æ„å’Œä¸­æ–­æ§åˆ¶ï¼Œè®© Claude Code çš„ç”¨æˆ·ä½“éªŒæ›´åŠ æµç•…å’Œå¯æ§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from typing import TypedDict, List, Annotated\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage, \n",
    "    SystemMessage, \n",
    "    AIMessage, \n",
    "    BaseMessage\n",
    ")\n",
    "\n",
    "# LLM\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatTongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"chapter-06-streaming-output\"\n",
    "\n",
    "# åˆå§‹åŒ–LLM\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# é€‰é¡¹2: é€šä¹‰åƒé—® (å–æ¶ˆæ³¨é‡Šä½¿ç”¨)\n",
    "llm = ChatTongyi(model=\"qwen3-max\", temperature=0)\n",
    "\n",
    "print(f\"âœ… LLMåˆå§‹åŒ–æˆåŠŸ: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åˆ›å»ºæµ‹è¯•Agent\n",
    "\n",
    "æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå¸¦æœ‰å¤šä¸ªå·¥å…·çš„Agentï¼Œç”¨äºæ¼”ç¤ºæµå¼è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸ºä»€ä¹ˆå·¥å…·è¦æœ‰å»¶è¿Ÿï¼Ÿ\n",
    "\n",
    "ä¸‹é¢å®šä¹‰çš„å·¥å…·éƒ½åŒ…å« `time.sleep()` å»¶è¿Ÿï¼Œè¿™æ˜¯ä¸ºäº†ï¼š\n",
    "\n",
    "1. **æ¨¡æ‹ŸçœŸå®ç¯å¢ƒ**ï¼šå®é™…çš„å·¥å…·æ“ä½œï¼ˆæ•°æ®åº“æŸ¥è¯¢ã€APIè°ƒç”¨ã€æ–‡ä»¶æ“ä½œç­‰ï¼‰éƒ½éœ€è¦æ—¶é—´\n",
    "2. **æ›´å¥½åœ°æ¼”ç¤ºæµå¼è¾“å‡º**ï¼šå¦‚æœå·¥å…·ç¬é—´å®Œæˆï¼Œå°±çœ‹ä¸åˆ°æµå¼è¿›åº¦è¿½è¸ªçš„æ•ˆæœ\n",
    "3. **ä½“éªŒç”¨æˆ·äº¤äº’**ï¼šåœ¨é•¿æ—¶é—´æ“ä½œä¸­ï¼Œç”¨æˆ·å¯ä»¥çœ‹åˆ°å®æ—¶åé¦ˆï¼Œç”šè‡³å¯ä»¥ä¸­æ–­æ“ä½œ\n",
    "\n",
    "**åœ¨å®é™…åº”ç”¨ä¸­**ï¼Œä½ ä¸éœ€è¦æ·»åŠ è¿™äº›äººå·¥å»¶è¿Ÿï¼ŒçœŸå®çš„å·¥å…·æ“ä½œæœ¬èº«å°±æœ‰å»¶è¿Ÿã€‚è¿™äº›å»¶è¿Ÿåªæ˜¯ä¸ºäº†è®©æ¼”ç¤ºæ•ˆæœæ›´åŠ æ˜æ˜¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ¨¡æ‹Ÿå·¥å…·ï¼ˆæœ‰å»¶è¿Ÿï¼Œæ–¹ä¾¿è§‚å¯Ÿæµå¼æ•ˆæœï¼‰\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"æœç´¢æ•°æ®åº“ï¼ˆæ¨¡æ‹Ÿï¼Œæœ‰2ç§’å»¶è¿Ÿï¼‰\n",
    "    \n",
    "    Args:\n",
    "        query: æœç´¢æŸ¥è¯¢\n",
    "    \"\"\"\n",
    "    time.sleep(2)  # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢è€—æ—¶\n",
    "    return f\"æ•°æ®åº“æœç´¢ç»“æœï¼šæ‰¾åˆ°å…³äº'{query}'çš„3æ¡è®°å½•\\n1. è®°å½•A\\n2. è®°å½•B\\n3. è®°å½•C\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ï¼ˆæ¨¡æ‹Ÿï¼Œæœ‰1ç§’å»¶è¿Ÿï¼‰\n",
    "    \n",
    "    Args:\n",
    "        expression: æ•°å­¦è¡¨è¾¾å¼\n",
    "    \"\"\"\n",
    "    time.sleep(1)  # æ¨¡æ‹Ÿè®¡ç®—è€—æ—¶\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"è®¡ç®—ç»“æœ: {expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"è®¡ç®—é”™è¯¯: {e}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_weather(city: str) -> str:\n",
    "    \"\"\"è·å–å¤©æ°”ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼Œæœ‰1.5ç§’å»¶è¿Ÿï¼‰\n",
    "    \n",
    "    Args:\n",
    "        city: åŸå¸‚åç§°\n",
    "    \"\"\"\n",
    "    time.sleep(1.5)  # æ¨¡æ‹ŸAPIè°ƒç”¨è€—æ—¶\n",
    "    return f\"{city}çš„å¤©æ°”ï¼šæ™´å¤©ï¼Œæ°”æ¸©25Â°Cï¼Œæ¹¿åº¦60%\"\n",
    "\n",
    "\n",
    "tools = [search_database, calculate, fetch_weather]\n",
    "\n",
    "print(f\"âœ… å®šä¹‰äº† {len(tools)} ä¸ªå·¥å…·\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºAgentï¼ˆå¸¦checkpointerï¼‰\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    "    prompt=\"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æœç´¢æ•°æ®åº“ã€è®¡ç®—æ•°å­¦è¡¨è¾¾å¼å’ŒæŸ¥è¯¢å¤©æ°”ã€‚è¯·å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚\",\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "print(\"âœ… Agentåˆ›å»ºå®Œæˆï¼ˆå¸¦checkpointerï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¨¡å¼ä¸€ï¼šstream_mode=\"values\"\n",
    "\n",
    "### ç‰¹ç‚¹\n",
    "- è¿”å›æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåçš„**å®Œæ•´çŠ¶æ€**\n",
    "- é€‚åˆè°ƒè¯•å’Œå®Œæ•´çŠ¶æ€è¿½è¸ª\n",
    "- æ•°æ®é‡è¾ƒå¤§\n",
    "\n",
    "### ä½¿ç”¨åœºæ™¯\n",
    "- è°ƒè¯•Agentè¡Œä¸º\n",
    "- æŸ¥çœ‹å®Œæ•´æ‰§è¡Œé“¾è·¯\n",
    "- è®°å½•å®Œæ•´çŠ¶æ€æ—¥å¿—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"æ¨¡å¼ä¸€ï¼šstream_mode='values'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-values\"}}\n",
    "input_msg = {\"messages\": [HumanMessage(content=\"è®¡ç®— 15 * 23\")]}\n",
    "\n",
    "print(\"\\nå¼€å§‹æµå¼æ‰§è¡Œ...\\n\")\n",
    "\n",
    "step = 0\n",
    "for chunk in agent.stream(input_msg, config, stream_mode=\"values\"):\n",
    "    step += 1\n",
    "    print(f\"\\n--- Step {step} ---\")\n",
    "    \n",
    "    # chunkæ˜¯å®Œæ•´çš„state\n",
    "    if \"messages\" in chunk:\n",
    "        last_msg = chunk[\"messages\"][-1]\n",
    "        print(f\"ç±»å‹: {last_msg.__class__.__name__}\")\n",
    "        \n",
    "        if hasattr(last_msg, 'content'):\n",
    "            content = last_msg.content\n",
    "            # é™åˆ¶æ˜¾ç¤ºé•¿åº¦\n",
    "            if len(content) > 100:\n",
    "                print(f\"å†…å®¹: {content[:100]}...\")\n",
    "            else:\n",
    "                print(f\"å†…å®¹: {content}\")\n",
    "        \n",
    "        if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "            print(f\"å·¥å…·è°ƒç”¨: {last_msg.tool_calls[0]['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"valuesæ¨¡å¼æ¼”ç¤ºå®Œæˆ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ¨¡å¼äºŒï¼šstream_mode=\"updates\"\n",
    "\n",
    "### ç‰¹ç‚¹\n",
    "- è¿”å›æ¯ä¸ªèŠ‚ç‚¹äº§ç”Ÿçš„**å¢é‡æ›´æ–°**\n",
    "- æ•°æ®é‡è¾ƒå°ï¼Œä¼ è¾“é«˜æ•ˆ\n",
    "- éœ€è¦è‡ªå·±ç»´æŠ¤å®Œæ•´çŠ¶æ€\n",
    "\n",
    "### ä½¿ç”¨åœºæ™¯\n",
    "- ç½‘ç»œä¼ è¾“ä¼˜åŒ–\n",
    "- å®æ—¶è¿›åº¦å±•ç¤º\n",
    "- å¢é‡æ›´æ–°UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"æ¨¡å¼äºŒï¼šstream_mode='updates'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-updates\"}}\n",
    "input_msg = {\"messages\": [HumanMessage(content=\"æœç´¢'LangGraphæ•™ç¨‹'\")]}\n",
    "\n",
    "print(\"\\nå¼€å§‹æµå¼æ‰§è¡Œ...\\n\")\n",
    "\n",
    "for chunk in agent.stream(input_msg, config, stream_mode=\"updates\"):\n",
    "    # chunkæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkeyæ˜¯èŠ‚ç‚¹åï¼Œvalueæ˜¯è¯¥èŠ‚ç‚¹çš„æ›´æ–°\n",
    "    for node_name, node_update in chunk.items():\n",
    "        print(f\"\\nğŸ“ èŠ‚ç‚¹: {node_name}\")\n",
    "        \n",
    "        if \"messages\" in node_update:\n",
    "            for msg in node_update[\"messages\"]:\n",
    "                print(f\"  ç±»å‹: {msg.__class__.__name__}\")\n",
    "                \n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    content = msg.content\n",
    "                    if len(content) > 80:\n",
    "                        print(f\"  å†…å®¹: {content[:80]}...\")\n",
    "                    else:\n",
    "                        print(f\"  å†…å®¹: {content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"updatesæ¨¡å¼æ¼”ç¤ºå®Œæˆ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¨¡å¼ä¸‰ï¼šstream_mode=\"messages\"\n",
    "\n",
    "### ç‰¹ç‚¹\n",
    "- è¿”å›**Tokençº§åˆ«**çš„æµå¼è¾“å‡º\n",
    "- æœ€æ¥è¿‘çœŸå®å¯¹è¯ä½“éªŒï¼ˆç±»ä¼¼ChatGPTï¼‰\n",
    "- å®æ—¶æ€§æœ€å¥½\n",
    "\n",
    "### ä½¿ç”¨åœºæ™¯\n",
    "- èŠå¤©ç•Œé¢\n",
    "- å®æ—¶æ‰“å­—æ•ˆæœ\n",
    "- æœ€ä½³ç”¨æˆ·ä½“éªŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"æ¨¡å¼ä¸‰ï¼šstream_mode='messages'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-messages\"}}\n",
    "input_msg = {\"messages\": [HumanMessage(content=\"ç”¨ä¸€å¥è¯ä»‹ç»LangGraph\")]}\n",
    "\n",
    "print(\"\\nğŸ¤– AI: \", end=\"\", flush=True)\n",
    "\n",
    "# messagesæ¨¡å¼è¿”å›çš„æ˜¯æ¶ˆæ¯æµ\n",
    "for msg, metadata in agent.stream(input_msg, config, stream_mode=\"messages\"):\n",
    "    # åªæ˜¾ç¤ºAIMessageçš„å†…å®¹\n",
    "    if isinstance(msg, AIMessage) and msg.content:\n",
    "        print(msg.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"messagesæ¨¡å¼æ¼”ç¤ºå®Œæˆï¼ˆå®æ—¶Tokenæµå¼ï¼‰\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 æ¨¡å¼å››ï¼šastream_events\n",
    "\n",
    "### ç‰¹ç‚¹\n",
    "- è¿”å›**äº‹ä»¶çº§åˆ«**çš„æµå¼è¾“å‡ºï¼ˆæ¯”Tokenæ›´ç»†ç²’åº¦ï¼‰\n",
    "- å¯ä»¥ç›‘å¬LLMå¼€å§‹ã€Tokenæµã€å·¥å…·è°ƒç”¨ç­‰å¤šç§äº‹ä»¶\n",
    "- æœ€é€‚åˆæ„å»ºç”Ÿäº§çº§åº”ç”¨\n",
    "- ä¸LangChainäº‹ä»¶æ ‡å‡†å…¼å®¹\n",
    "\n",
    "### ä½¿ç”¨åœºæ™¯\n",
    "- éœ€è¦ç²¾ç¡®æ§åˆ¶æ¯ä¸ªæ‰§è¡Œé˜¶æ®µ\n",
    "- æ˜¾ç¤ºå·¥å…·è°ƒç”¨çš„å¼€å§‹å’Œç»“æŸ\n",
    "- æ„å»ºç±»ä¼¼Claude Codeçš„äº¤äº’ä½“éªŒ\n",
    "- ç”Ÿäº§ç¯å¢ƒçš„ç›‘æ§å’Œè°ƒè¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"æ¨¡å¼å››ï¼šastream_eventsï¼ˆäº‹ä»¶çº§æµå¼ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-events\"}}\n",
    "input_msg = {\"messages\": [HumanMessage(content=\"è®¡ç®— 20 * 15\")]}\n",
    "\n",
    "print(\"\\nå¼€å§‹æµå¼æ‰§è¡Œ...\\n\")\n",
    "all_events = []\n",
    "# astream_eventsè¿”å›ä¸åŒç±»å‹çš„äº‹ä»¶\n",
    "async for event in agent.astream_events(input_msg, config, version=\"v2\"):\n",
    "    all_events.append(event)\n",
    "    event_type = event[\"event\"]\n",
    "    \n",
    "    # 1. LLMå¼€å§‹ç”Ÿæˆ\n",
    "    if event_type == \"on_chat_model_start\":\n",
    "        print(\"ğŸ¤” AIå¼€å§‹æ€è€ƒ...\")\n",
    "    \n",
    "    # 2. LLMæµå¼è¾“å‡ºï¼ˆTokençº§åˆ«ï¼‰\n",
    "    elif event_type == \"on_chat_model_stream\":\n",
    "        chunk = event[\"data\"][\"chunk\"]\n",
    "        if hasattr(chunk, \"content\") and chunk.content:\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "    \n",
    "    # 3. LLMç”Ÿæˆç»“æŸ\n",
    "    elif event_type == \"on_chat_model_end\":\n",
    "        print()  # æ¢è¡Œ\n",
    "    \n",
    "    # 4. å·¥å…·å¼€å§‹æ‰§è¡Œ\n",
    "    elif event_type == \"on_tool_start\":\n",
    "        tool_name = event[\"name\"]\n",
    "        print(f\"\\nğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}\")\n",
    "    \n",
    "    # 5. å·¥å…·æ‰§è¡Œç»“æŸ\n",
    "    elif event_type == \"on_tool_end\":\n",
    "        tool_name = event[\"name\"]\n",
    "        print(f\"âœ… å·¥å…·å®Œæˆ: {tool_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"astream_eventsæ¼”ç¤ºå®Œæˆ\")\n",
    "print(\"ç‰¹ç‚¹: å¯ä»¥ç²¾ç¡®æ§åˆ¶æ¯ä¸ªé˜¶æ®µçš„è¾“å‡ºï¼\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¼‚æ­¥æµå¼è¾“å‡º\n",
    "\n",
    "ä½¿ç”¨`astream()`å®ç°å¼‚æ­¥æµå¼ï¼Œé€‚åˆå¹¶å‘åœºæ™¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_stream_demo():\n",
    "    \"\"\"å¼‚æ­¥æµå¼æ¼”ç¤º\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"å¼‚æ­¥æµå¼è¾“å‡ºæ¼”ç¤º\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"test-async\"}}\n",
    "    input_msg = {\"messages\": [HumanMessage(content=\"æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”\")]}\n",
    "    \n",
    "    print(\"\\nğŸ¤– AI: \", end=\"\", flush=True)\n",
    "    \n",
    "    # ä½¿ç”¨astreamè¿›è¡Œå¼‚æ­¥æµå¼\n",
    "    async for msg, metadata in agent.astream(input_msg, config, stream_mode=\"messages\"):\n",
    "        if isinstance(msg, AIMessage) and msg.content:\n",
    "            print(msg.content, end=\"\", flush=True)\n",
    "            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–å¼‚æ­¥æ“ä½œ\n",
    "            await asyncio.sleep(0)  # yield control\n",
    "    \n",
    "    print(\"\\n\\nâœ… å¼‚æ­¥æµå¼å®Œæˆ\")\n",
    "\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥å‡½æ•°\n",
    "await async_stream_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æµå¼è¿›åº¦è¿½è¸ª\n",
    "\n",
    "å®æ—¶æ˜¾ç¤ºAgentæ‰§è¡Œè¿›åº¦ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹è½¬æ¢å’Œå·¥å…·è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_with_progress():\n",
    "    \"\"\"å¸¦è¿›åº¦è¿½è¸ªçš„æµå¼æ‰§è¡Œ\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"æµå¼è¿›åº¦è¿½è¸ªæ¼”ç¤º\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"progress-demo\"}}\n",
    "    input_msg = {\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"æœç´¢'æœºå™¨å­¦ä¹ 'ï¼Œç„¶åè®¡ç®—100*50\"\n",
    "        )]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nğŸ“Š æ‰§è¡Œè¿½è¸ªï¼š\\n\")\n",
    "    \n",
    "    node_count = {}\n",
    "    tool_calls = []\n",
    "    \n",
    "    for chunk in agent.stream(input_msg, config, stream_mode=\"updates\"):\n",
    "        for node_name, node_update in chunk.items():\n",
    "            # ç»Ÿè®¡èŠ‚ç‚¹æ‰§è¡Œæ¬¡æ•°\n",
    "            node_count[node_name] = node_count.get(node_name, 0) + 1\n",
    "            \n",
    "            print(f\"âœ“ èŠ‚ç‚¹ [{node_name}] æ‰§è¡Œä¸­...\")\n",
    "            \n",
    "            # æ£€æŸ¥å·¥å…·è°ƒç”¨\n",
    "            if \"messages\" in node_update:\n",
    "                for msg in node_update[\"messages\"]:\n",
    "                    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                        for tool_call in msg.tool_calls:\n",
    "                            tool_name = tool_call['name']\n",
    "                            tool_calls.append(tool_name)\n",
    "                            print(f\"  ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"æ‰§è¡Œç»Ÿè®¡\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nèŠ‚ç‚¹æ‰§è¡Œæ¬¡æ•°:\")\n",
    "    for node, count in node_count.items():\n",
    "        print(f\"  {node}: {count}æ¬¡\")\n",
    "    \n",
    "    print(f\"\\nå·¥å…·è°ƒç”¨é¡ºåº:\")\n",
    "    for i, tool in enumerate(tool_calls, 1):\n",
    "        print(f\"  {i}. {tool}\")\n",
    "\n",
    "\n",
    "stream_with_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Steering åŸºç¡€å®ç°ï¼ˆ15åˆ†é’Ÿï¼‰\n",
    "\n",
    "### ç¬¬ä¸€ä¸ª Steering Demo\n",
    "\n",
    "è¿™æ˜¯æˆ‘ä»¬å®ç°çš„ç¬¬ä¸€ä¸ª Steering Demoï¼Œä½¿ç”¨æœ€ç®€å•çš„æ–¹å¼å®ç°äº†æµå¼è¾“å‡ºå’Œä¸­æ–­åŠŸèƒ½ã€‚  \n",
    "å› ä¸º `steering_demo/` å·²ç»æä¾›äº†**å®Œæ•´å®ç°**ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- åç«¯(backend.py)ï¼šFastAPI + SSE + Abort æœºåˆ¶\n",
    "- å‰ç«¯(frontend.html)ï¼šåŸç”Ÿ JS + æµå¼æ˜¾ç¤º + ä¸­æ–­æŒ‰é’®\n",
    "- å®Œæ•´æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜\n",
    "\n",
    "**æ‰€ä»¥è¿™é‡Œåªå±•ç¤ºæ ¸å¿ƒåŸç†ï¼Œå®Œæ•´ä»£ç è¯·ç›´æ¥è¿è¡Œ steering_demo æŸ¥çœ‹å’Œå­¦ä¹ ï¼**\n",
    "\n",
    "**ğŸ¯ æ ¸å¿ƒå…¬å¼**ï¼š\n",
    "\n",
    "```\n",
    "Steering = æµå¼è¾“å‡º + ä¸­æ–­æœºåˆ¶ + çŠ¶æ€æ¢å¤\n",
    "```\n",
    "\n",
    "**ğŸ“Œ ä¸‰å¤§æ ¸å¿ƒç»„ä»¶**ï¼š\n",
    "\n",
    "| ç»„ä»¶ | ä½œç”¨ | å…³é”®å®ç° |\n",
    "|------|------|---------|\n",
    "| **Abort Flag** | ä¸­æ–­ä¿¡å· | å…¨å±€å­—å…¸ `{session_id: bool}` |\n",
    "| **Checkpointer** | çŠ¶æ€æŒä¹…åŒ– | `MemorySaver()` æˆ– `RedisSaver()` |\n",
    "| **Thread ID** | ä¼šè¯éš”ç¦»/çŠ¶æ€æ¢å¤ | æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„ `thread_id` |\n",
    "\n",
    "**ğŸ’¡ æ ¸å¿ƒæœºåˆ¶**ï¼š\n",
    "\n",
    "```python\n",
    "# 1. å…¨å±€ä¸­æ–­æ ‡å¿—\n",
    "abort_flags: Dict[str, bool] = {}\n",
    "\n",
    "# 2. åœ¨æµå¼è¾“å‡º(/api/chat)å¾ªç¯ä¸­æ£€æŸ¥æ ‡å¿—\n",
    "async for msg, _ in agent.astream(input, config, stream_mode=\"messages\"):\n",
    "    if abort_flags.get(session_id, False):  # æ£€æŸ¥ä¸­æ–­æ ‡å¿—\n",
    "        yield f\"event: aborted\\ndata: å·²ä¸­æ–­\\n\\n\"\n",
    "        break  # ç«‹å³åœæ­¢è¾“å‡º\n",
    "\n",
    "    if isinstance(msg, AIMessage) and msg.content:\n",
    "        yield f\"event: token\\ndata: {msg.content}\\n\\n\"\n",
    "\n",
    "# 3. åœ¨å¦ä¸€ä¸ªçº¿ç¨‹(/api/abort)ä¸­è®¾ç½®å…¨å±€ä¸­æ–­æ ‡å¿—\n",
    "async def abort_chat(request: AbortRequest):\n",
    "    session_id = request.session_id\n",
    "    abort_flags[session_id] = True\n",
    "```\n",
    "\n",
    "**æ¶æ„å›¾**ï¼š\n",
    "\n",
    "```\n",
    "å‰ç«¯                         åç«¯\n",
    "  â”‚                           â”‚\n",
    "  â”œâ”€ POST /api/chat â”€â”€â”€â”€â”€â”€â”€â”€> åˆ›å»ºæµå¼è¾“å‡º\n",
    "  â”‚                           â”œâ”€ abort_flags[session_id] = False\n",
    "  â”‚                           â”œâ”€ async for msg in astream():\n",
    "  â”‚                           â”‚    if abort_flags[session_id]:\n",
    "  â”‚                           â”‚        break  # ç«‹å³åœæ­¢\n",
    "  â”‚                           â””â”€ yield tokens...\n",
    "  â”‚                           â”‚\n",
    "  â”œâ”€ POST /api/abort â”€â”€â”€â”€â”€â”€â”€> è®¾ç½®ä¸­æ–­æ ‡å¿—\n",
    "  â”‚                           abort_flags[session_id] = True\n",
    "  â”‚                           â”‚\n",
    "  â”œâ”€ æ¥æ”¶ event: aborted â”€â”€â”€â”€< æµå¼å¾ªç¯æ£€æµ‹åˆ°æ ‡å¿—\n",
    "  â””â”€ æ˜¾ç¤º\"å·²ä¸­æ–­\"              break é€€å‡ºå¾ªç¯\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steering_demoçš„å±€é™æ€§\n",
    "\n",
    "**âœ… èƒ½åšåˆ°**ï¼š\n",
    "- ä¸­æ–­ LLM çš„æµå¼è¾“å‡ºï¼ˆåœæ­¢æ˜¾ç¤º tokenï¼‰\n",
    "- ä¿å­˜çŠ¶æ€ï¼ˆä½¿ç”¨ checkpointerï¼‰\n",
    "- æ¢å¤å¯¹è¯ï¼ˆä¸‹æ¬¡è¯·æ±‚è‡ªåŠ¨ä»æ£€æŸ¥ç‚¹ç»§ç»­ï¼‰\n",
    "\n",
    "**âŒ æ— æ³•åšåˆ°**ï¼š\n",
    "- **æ— æ³•ä¸­æ–­å·¥å…·æ‰§è¡Œ** - è¿™æ˜¯æœ€å¤§çš„é—®é¢˜ï¼\n",
    "\n",
    "**ğŸ¯ é—®é¢˜æ¼”ç¤º**ï¼š\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    \"\"\"åœ¨æ•°æ®åº“ä¸­æœç´¢ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿ2ç§’å»¶è¿Ÿï¼‰\"\"\"\n",
    "    for i in range(10):\n",
    "        print(f\"ğŸ” æœç´¢: {query} {i}\")\n",
    "        time.sleep(1)\n",
    "    return f\"æ‰¾åˆ°å…³äº '{query}' çš„ 3 æ¡ç»“æœï¼šç»“æœ1ã€ç»“æœ2ã€ç»“æœ3\"\n",
    "\n",
    "# ç”¨æˆ·åœºæ™¯ï¼š\n",
    "# 1. å‘é€ \"æœç´¢ Python\"\n",
    "# 2. LLM å†³å®šè°ƒç”¨ search_database å·¥å…·\n",
    "# 3. å·¥å…·å¼€å§‹æ‰§è¡Œï¼ˆéœ€è¦ 10 ç§’ï¼‰\n",
    "# 4. ç”¨æˆ·åœ¨ç¬¬ 2 ç§’ç‚¹å‡»ğŸ›‘åœæ­¢\n",
    "# 5. âŒ é—®é¢˜ï¼šå·¥å…·ä»åœ¨åå°è¿è¡Œï¼(æŸ¥çœ‹åå°è¾“å‡º)\n",
    "#    - abort_flags åªèƒ½åœæ­¢è¾“å‡ºå¾ªç¯\n",
    "#    - å·¥å…·æ— æ³•è¢«æ‰“æ–­ï¼Œä¼šä¸€ç›´è¿è¡Œåˆ°å®Œæˆä¼šä¸€ç›´è¿è¡Œåˆ°å®Œæˆ\n",
    "```\n",
    "\n",
    "**ä¸ºä»€ä¹ˆå·¥å…·æ— æ³•è¢«ä¸­æ–­ï¼Ÿ**\n",
    "\n",
    "å·¥å…·æ‰§è¡Œä½äºAgent graphçš„ä¸€ä¸ªèŠ‚ç‚¹ä¸­ï¼Œastreamå¼€å§‹è¾“å‡ºæ—¶å®é™…ä¸Šå·²ç»æ‰§è¡Œå®Œtooläº†ï¼Œåªæœ‰åœ¨astreamå¼€å§‹è¾“å‡ºåï¼Œæˆ‘ä»¬æ‰å¼€å§‹æ£€æµ‹ä¸­æ–­ä¿¡å·ï¼Œæ¢è¨€ä¹‹ï¼Œåœ¨toolæ‰§è¡Œæ—¶ï¼Œä»£ç è¿˜æ²¡è¿è¡Œåˆ°astreamçš„å¾ªç¯ä¸­ï¼Œæ— æ³•æ£€æµ‹ä¸­æ–­ä¿¡å·ï¼Œå› æ­¤ä¸èƒ½ä¸­æ–­å·¥å…·ã€‚  \n",
    "\n",
    "å¦ä¸€æ–¹é¢ï¼Œå³ä½¿å°†**ä¸­æ–­ä¿¡å·æ£€æµ‹**æ”¾åˆ°å·¥å…·æ‰§è¡Œæµç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿå¾ˆéš¾æ§åˆ¶ä¸­æ–­çš„æ—¶æœºï¼Œæ¯”å¦‚å°†ä¿¡å·æ£€æµ‹æ”¾åœ¨ä¸€ä¸ªè€—æ—¶1å°æ—¶çš„è®¡ç®—ä»»åŠ¡çš„å‰æˆ–åï¼Œåªè¦è®¡ç®—ä»»åŠ¡å¼€å§‹æ‰§è¡Œï¼Œæˆ‘ä»¬å°±æ²¡æ³•ä¸­æ–­ã€‚\n",
    "\n",
    "åº”è¯¥å¦‚ä½•ä¸­æ–­ï¼Ÿæˆ‘ä»¬ç»§ç»­çœ‹ä¸‹ä¸€ç« èŠ‚ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è§£å†³æ–¹æ¡ˆï¼šå¼‚æ­¥å·¥å…· + Task å–æ¶ˆæœºåˆ¶\n",
    "\n",
    "è¦çœŸæ­£å®ç°å¯ä¸­æ–­çš„å·¥å…·æ‰§è¡Œï¼Œéœ€è¦ä¸¤ä¸ªæ ¸å¿ƒæ”¹é€ ï¼š\n",
    "\n",
    "**ğŸ”‘ æ”¹é€  1ï¼šå°†åŒæ­¥å·¥å…·è½¬æ¢ä¸ºå¼‚æ­¥å·¥å…·**\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆæœ¬ï¼šåŒæ­¥å·¥å…·ï¼ˆä¸å¯ä¸­æ–­ï¼‰\n",
    "@tool\n",
    "def search_database(query: str) -> str:\n",
    "    time.sleep(5)  # é˜»å¡æ•´ä¸ªè¿›ç¨‹\n",
    "    return \"ç»“æœ\"\n",
    "\n",
    "# âœ… æ–°ç‰ˆæœ¬ï¼šå¼‚æ­¥å·¥å…·ï¼ˆå¯ä¸­æ–­ï¼‰\n",
    "@tool\n",
    "async def search_database(query: str) -> str:\n",
    "    await asyncio.sleep(5)  # è¿™ä¸ªä½ç½®å¯é€šè¿‡task.cancel()ä¸­æ–­\n",
    "    return \"ç»“æœ\"\n",
    "```\n",
    "\n",
    "**ä¸ºä»€ä¹ˆå¼‚æ­¥å¯ä»¥è¢«ä¸­æ–­ï¼Ÿ**\n",
    "\n",
    "```\n",
    "åŒæ­¥ time.sleep(5):\n",
    "  è¿›ç¨‹ â†’ å®Œå…¨é˜»å¡ â†’ ä»€ä¹ˆéƒ½åšä¸äº† âŒ\n",
    "\n",
    "å¼‚æ­¥ await asyncio.sleep(5):\n",
    "  ä»»åŠ¡ â†’ æš‚åœå½“å‰ä»»åŠ¡ â†’ CPU å¤„ç†å…¶ä»–ä»»åŠ¡ âœ…\n",
    "       â†’ å¯ä»¥æ¥æ”¶å–æ¶ˆä¿¡å· â†’ æŠ›å‡º CancelledError âœ…\n",
    "```\n",
    "\n",
    "**ğŸ”‘ æ”¹é€  2ï¼šä½¿ç”¨ asyncio.Task ç®¡ç†æ‰§è¡Œ**\n",
    "\n",
    "```python\n",
    "# âŒ æ—§ç‰ˆæœ¬ï¼šä½¿ç”¨å¸ƒå°”æ ‡å¿—\n",
    "abort_flags = {session_id: False}\n",
    "\n",
    "async for msg, _ in agent.astream(input, config):\n",
    "    if abort_flags[session_id]:  # åªæ˜¯æ£€æŸ¥æ ‡å¿—\n",
    "        break  # å·¥å…·ä»åœ¨åå°è¿è¡Œ âŒ\n",
    "\n",
    "# âœ… æ–°ç‰ˆæœ¬ï¼šä½¿ç”¨ Task ç®¡ç†\n",
    "running_sessions = {}  # {session_id: asyncio.Task}\n",
    "\n",
    "# å°† agent æ‰§è¡ŒåŒ…è£…æˆ Task\n",
    "task = asyncio.create_task(run_agent())\n",
    "running_sessions[session_id] = task\n",
    "\n",
    "# ä¸­æ–­æ—¶ï¼Œç›´æ¥å–æ¶ˆ Task\n",
    "task.cancel()  # å‘é€ CancelledError åˆ°å·¥å…·å†…éƒ¨ âœ…\n",
    "```\n",
    "\n",
    "**æ ¸å¿ƒåŸç†å›¾**ï¼š\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         å¼‚æ­¥å¯ä¸­æ–­æ¶æ„                           â”‚\n",
    "â”‚                                                  â”‚\n",
    "â”‚  ç”¨æˆ·ç‚¹å‡»åœæ­¢                                     â”‚\n",
    "â”‚    â†“                                             â”‚\n",
    "â”‚  è°ƒç”¨ /api/abort â†’ è®¾ç½®æ ‡å¿— + task.cancel()      â”‚\n",
    "â”‚    â†“                                             â”‚\n",
    "â”‚  asyncio å‘ Task æ³¨å…¥ CancelledError             â”‚\n",
    "â”‚    â†“                                             â”‚\n",
    "â”‚  å·¥å…·å†…éƒ¨ await asyncio.sleep() å¤„æ•è·å¼‚å¸¸       â”‚\n",
    "â”‚    â†“                                             â”‚\n",
    "â”‚  except asyncio.CancelledError: â† æ•è·å–æ¶ˆä¿¡å·   â”‚\n",
    "â”‚      return \"æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­\"  â† ä¼˜é›…é€€å‡º         â”‚\n",
    "â”‚    â†“                                             â”‚\n",
    "â”‚  Agent ç«‹å³åœæ­¢ï¼Œé‡Šæ”¾èµ„æº âœ…                      â”‚\n",
    "â”‚    â†“                                             â”‚\n",
    "â”‚  å¤„ç†ç”¨æˆ·çš„æ–°æ¶ˆæ¯ âœ…                              â”‚\n",
    "â”‚                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### å°ç»“\n",
    "\n",
    "steering_demo å®ç°äº† Steering çš„åŸºç¡€æ¡†æ¶ï¼š\n",
    "- âœ… æµå¼è¾“å‡º\n",
    "- âœ… ä¸­æ–­ä¿¡å·æœºåˆ¶ï¼ˆabort_flagsï¼‰\n",
    "- âœ… çŠ¶æ€æŒä¹…åŒ–ï¼ˆcheckpointerï¼‰\n",
    "\n",
    "ä½†å­˜åœ¨å…³é”®ç¼ºé™·ï¼š\n",
    "- âŒ æ— æ³•çœŸæ­£ä¸­æ–­å·¥å…·æ‰§è¡Œ\n",
    "- âŒ å·¥å…·ä¼šåœ¨åå°ç»§ç»­è¿è¡Œï¼Œæµªè´¹èµ„æº\n",
    "\n",
    "è§£å†³æ–¹æ¡ˆï¼šå¼‚æ­¥å·¥å…· + Task å–æ¶ˆæœºåˆ¶  \n",
    "**å®Œæ•´å®ç°ä¼šæ”¾åœ¨åç»­çš„é«˜çº§æ•™ç¨‹ä¸­**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. æ ¸å¿ƒæ¦‚å¿µæ€»ç»“\n",
    "\n",
    "### å››ç§Streamæ¨¡å¼å¯¹æ¯”\n",
    "\n",
    "| æ¨¡å¼ | è¿”å›å†…å®¹ | ç²’åº¦ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|---------|------|----------|\n",
    "| values | å®Œæ•´çŠ¶æ€ | èŠ‚ç‚¹çº§ | è°ƒè¯•ã€æ—¥å¿—è®°å½• |\n",
    "| updates | å¢é‡æ›´æ–° | èŠ‚ç‚¹çº§ | è¿›åº¦è¿½è¸ªã€ä¼ è¾“ä¼˜åŒ– |\n",
    "| messages | Tokenæµ | Tokençº§ | èŠå¤©ç•Œé¢ã€å®æ—¶æ‰“å­—æ•ˆæœ |\n",
    "| astream_events | äº‹ä»¶æµ | äº‹ä»¶çº§ | ç”Ÿäº§ç¯å¢ƒã€ç²¾ç¡®æ§åˆ¶ |\n",
    "\n",
    "### astream_events vs messages\n",
    "\n",
    "```python\n",
    "# messagesæ¨¡å¼ï¼šåªèƒ½è·å–Tokenæµ\n",
    "for msg, metadata in agent.stream(..., stream_mode=\"messages\"):\n",
    "    print(msg.content, end=\"\")  # åªæœ‰å†…å®¹\n",
    "\n",
    "# astream_eventsï¼šå¯ä»¥ç›‘å¬æ‰€æœ‰äº‹ä»¶\n",
    "async for event in agent.astream_events(..., version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_tool_start\":\n",
    "        print(f\"å·¥å…·å¼€å§‹: {event['name']}\")  # âœ… å¯ä»¥çŸ¥é“å·¥å…·ä½•æ—¶å¼€å§‹\n",
    "    elif event[\"event\"] == \"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"\")\n",
    "```\n",
    "\n",
    "### æµå¼è¾“å‡ºçš„ä¼˜åŠ¿\n",
    "\n",
    "1. **ç”¨æˆ·ä½“éªŒ**: å®æ—¶åé¦ˆ vs é»‘ç›’ç­‰å¾…\n",
    "2. **å¯è§‚æµ‹æ€§**: æ¸…æ™°çœ‹åˆ°æ‰§è¡Œè¿‡ç¨‹\n",
    "3. **æ€§èƒ½æ„ŸçŸ¥**: é™ä½ç­‰å¾…çš„å¿ƒç†æ—¶é—´\n",
    "\n",
    "\n",
    "### åŒæ­¥ vs å¼‚æ­¥\n",
    "\n",
    "```python\n",
    "# åŒæ­¥æµå¼\n",
    "for chunk in agent.stream(...):\n",
    "    process(chunk)\n",
    "\n",
    "# å¼‚æ­¥æµå¼ï¼ˆæ¨èç”¨äºå¹¶å‘åœºæ™¯ï¼‰\n",
    "async for chunk in agent.astream(...):\n",
    "    await async_process(chunk)\n",
    "\n",
    "# astream_eventsï¼ˆå¿…é¡»å¼‚æ­¥ï¼‰\n",
    "async for event in agent.astream_events(..., version=\"v2\"):\n",
    "    handle_event(event)\n",
    "```\n",
    "\n",
    "### steeringæœºåˆ¶\n",
    "1. ä¸€ä¸ªç®€å•çš„steering_demo, backend.py+frontend.html, å±•ç¤ºè¾“å‡ºæµä¸­æ–­ã€‚\n",
    "2. ä¸€ä¸ªçœŸæ­£çš„steeringæœºåˆ¶çš„è§£å†³æ–¹æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ç»ƒä¹ é¢˜\n",
    "\n",
    "### ç»ƒä¹ 1: è‡ªå®šä¹‰äº‹ä»¶è¿‡æ»¤å™¨\n",
    "å®ç°ä¸€ä¸ªäº‹ä»¶è¿‡æ»¤å™¨ï¼Œåªæ˜¾ç¤ºç‰¹å®šç±»å‹çš„äº‹ä»¶ï¼ˆå¦‚åªæ˜¾ç¤ºå·¥å…·è°ƒç”¨äº‹ä»¶ï¼‰ã€‚\n",
    "\n",
    "**æç¤º**:\n",
    "```python\n",
    "async def filtered_stream(agent, input_msg, config, event_types: List[str]):\n",
    "    \"\"\"åªè¾“å‡ºæŒ‡å®šç±»å‹çš„äº‹ä»¶\"\"\"\n",
    "    async for event in agent.astream_events(input_msg, config, version=\"v2\"):\n",
    "        if event[\"event\"] in event_types:\n",
    "            yield event\n",
    "```\n",
    "\n",
    "### ç»ƒä¹ 2: æµå¼è¿›åº¦æ¡\n",
    "ä½¿ç”¨ `ipywidgets` å®ç°ä¸€ä¸ªçœŸå®çš„è¿›åº¦æ¡ï¼Œå®æ—¶æ˜¾ç¤ºAgentæ‰§è¡Œè¿›åº¦ã€‚\n",
    "\n",
    "**æç¤º**:\n",
    "```python\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "progress = widgets.IntProgress(min=0, max=100, description='æ‰§è¡Œä¸­:')\n",
    "display(progress)\n",
    "\n",
    "# åœ¨æµå¼å¾ªç¯ä¸­æ›´æ–°è¿›åº¦\n",
    "progress.value = current_step / total_steps * 100\n",
    "```\n",
    "\n",
    "### ç»ƒä¹ 3: å¸¦è¶…æ—¶çš„å¼‚æ­¥å·¥å…·\n",
    "å®ç°ä¸€ä¸ªå¸¦è¶…æ—¶æœºåˆ¶çš„å¼‚æ­¥å·¥å…·ï¼Œå¦‚æœæ‰§è¡Œè¶…è¿‡æŒ‡å®šæ—¶é—´è‡ªåŠ¨ä¸­æ–­ã€‚\n",
    "\n",
    "**æç¤º**:\n",
    "```python\n",
    "@tool\n",
    "async def search_with_timeout(query: str, timeout: int = 5) -> str:\n",
    "    \"\"\"å¸¦è¶…æ—¶çš„æœç´¢å·¥å…·\"\"\"\n",
    "    try:\n",
    "        result = await asyncio.wait_for(\n",
    "            actual_search(query), \n",
    "            timeout=timeout\n",
    "        )\n",
    "        return result\n",
    "    except asyncio.TimeoutError:\n",
    "        return f\"æœç´¢è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰\"\n",
    "```\n",
    "\n",
    "### ç»ƒä¹ 4: å®ç°çœŸæ­£çš„å¯ä¸­æ–­å·¥å…·\n",
    "å‚è€ƒç¬¬9ç« çš„è§£å†³æ–¹æ¡ˆï¼Œå®ç°ä¸€ä¸ªä½¿ç”¨ `asyncio.Task` çš„å®Œæ•´å¯ä¸­æ–­ç³»ç»Ÿã€‚\n",
    "\n",
    "**æ ¸å¿ƒæ­¥éª¤**:\n",
    "1. å°†æ‰€æœ‰å·¥å…·æ”¹ä¸ºå¼‚æ­¥\n",
    "2. ä½¿ç”¨ `asyncio.create_task()` åŒ…è£…æ‰§è¡Œ\n",
    "3. åœ¨ä¸­æ–­æ—¶è°ƒç”¨ `task.cancel()`\n",
    "4. åœ¨å·¥å…·å†…éƒ¨æ•è· `CancelledError`\n",
    "\n",
    "### æ€è€ƒé¢˜\n",
    "   \n",
    "1. **å¦‚ä½•å¹³è¡¡æµå¼è¾“å‡ºçš„å®æ—¶æ€§å’Œæ€§èƒ½å¼€é”€ï¼Ÿ**\n",
    "   - æç¤ºï¼šæ‰¹é‡å‘é€ vs é€ä¸ªå‘é€çš„æƒè¡¡\n",
    "\n",
    "2. **åœ¨å¤šç”¨æˆ·åœºæ™¯ä¸‹ï¼Œå¦‚ä½•ç¡®ä¿æ¯ä¸ªç”¨æˆ·çš„æµå¼è¾“å‡ºäº’ä¸å¹²æ‰°ï¼Ÿ**\n",
    "   - æç¤ºï¼šæ€è€ƒ `thread_id` å’Œ `session_id` çš„ä½œç”¨\n",
    "\n",
    "3. **å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œä¸­æ–­æœºåˆ¶åº”è¯¥å¦‚ä½•å¤„ç†ï¼Ÿ**\n",
    "   - ä¿å­˜ä¸­é—´çŠ¶æ€ï¼Ÿé‡è¯•ï¼Ÿç›´æ¥è¿”å›é”™è¯¯ï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ä¸‹ä¸€æ­¥\n",
    "\n",
    "é€šè¿‡å‰é¢çš„å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†æ„å»ºæ™ºèƒ½Agentçš„æ ¸å¿ƒæŠ€èƒ½ï¼š\n",
    "- âœ… ç¬¬1ç« ï¼šåŸºç¡€ReAct Agent - å·¥å…·è°ƒç”¨\n",
    "- âœ… ç¬¬2ç« ï¼šäººç±»åé¦ˆ - ä¸­æ–­å’Œå®¡æ‰¹\n",
    "- âœ… ç¬¬3ç« ï¼šå­Agent - æ¨¡å—åŒ–è®¾è®¡\n",
    "- âœ… ç¬¬4ç« ï¼šä»»åŠ¡ç®¡ç† - Todoç³»ç»Ÿ\n",
    "- âœ… ç¬¬5ç« ï¼šä¸Šä¸‹æ–‡å‹ç¼© - é•¿å¯¹è¯å¤„ç†\n",
    "- âœ… ç¬¬6ç« ï¼šæµå¼è¾“å‡ºå’Œä¸­æ–­ - å®æ—¶å“åº”\n",
    "\n",
    "æ¥ä¸‹æ¥å»ºè®®:\n",
    "1. æ¢ç´¢æœ¬é¡¹ç›®ç›®å½•ä¸‹çš„claude_code_demoï¼Œè¯¥demoæ•´åˆäº†ä¸Šé¢æ‰€æœ‰çš„åŠŸèƒ½ç‰¹å¾ã€‚è¯·å°è¯•è¿è¡Œã€è°ƒè¯•ã€æ”¹é€ è¯¥é¡¹ç›®ã€‚\n",
    "2. æ€è€ƒè·ç¦»çœŸæ­£çš„claude codeè¿˜æœ‰å¤šå¤§å·®è·ï¼Œä½ å¯ä»¥å‚è€ƒé¡¹ç›®ç›®å½•ä¸‹çš„è¡¥å……ææ–™[`supp1`](supp1_from_course_to_production.md)ã€‚\n",
    "\n",
    "Happy Learning! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}