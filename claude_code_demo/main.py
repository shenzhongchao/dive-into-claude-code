"""
Claude Code Demo - ä¸»å…¥å£
åŸºäº Python LangGraph å®ç°çš„ Claude Code æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º
"""
import asyncio
import uuid
import sys
import os
from typing import Optional


from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatTongyi

# å°è¯•ç›¸å¯¹å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ç»å¯¹å¯¼å…¥

from config import ClaudeCodeConfig, get_default_config
from core.graph import build_graph, visualize_graph
from core.state import create_initial_state


# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
def setup_console_encoding():
    """è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸º UTF-8"""
    if sys.platform == "win32":
        try:
            # è®¾ç½®æ§åˆ¶å°ä»£ç é¡µä¸º UTF-8
            os.system("chcp 65001 > nul")
            # é‡æ–°é…ç½®æ ‡å‡†è¾“å‡º
            if hasattr(sys.stdout, 'reconfigure'):
                sys.stdout.reconfigure(encoding='utf-8')
            if hasattr(sys.stderr, 'reconfigure'):
                sys.stderr.reconfigure(encoding='utf-8')
        except Exception:
            pass


def safe_print(text: str, **kwargs):
    """å®‰å…¨æ‰“å°ï¼Œå¤„ç† Windows æ§åˆ¶å°ç¼–ç é—®é¢˜"""
    try:
        print(text, **kwargs)
    except UnicodeEncodeError:
        # åœ¨ Windows ä¸Šç§»é™¤ä¸æ”¯æŒçš„å­—ç¬¦
        text = text.encode(sys.stdout.encoding or 'utf-8', errors='replace').decode(sys.stdout.encoding or 'utf-8')
        print(text, **kwargs)


class ClaudeCodeDemo:
    """Claude Code Demo åº”ç”¨"""

    def __init__(self, config: Optional[ClaudeCodeConfig] = None):
        """
        åˆå§‹åŒ–åº”ç”¨

        Args:
            config: é…ç½®å¯¹è±¡ï¼Œé»˜è®¤ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or get_default_config()

        # åˆå§‹åŒ– LLM
        self.llm = self._init_llm()

        # æ„å»ºå›¾
        self.app = build_graph(self.config, self.llm)

        safe_print("âœ… Claude Code Demo initialized")
        safe_print(f"   LLM: {self.config.llm.provider} - {self.config.llm.model}")
        safe_print(f"   Max tokens: {self.config.token.max_context_tokens}")
        safe_print(f"   Compression threshold: {self.config.token.compression_threshold}")

    def _init_llm(self):
        """åˆå§‹åŒ–è¯­è¨€æ¨¡å‹"""
        if self.config.llm.provider == "openai":
            return ChatOpenAI(
                model=self.config.llm.model,
                temperature=self.config.llm.temperature,
                api_key=self.config.llm.api_key
            )
        elif self.config.llm.provider == "tongyi":
            return ChatTongyi(
                model=self.config.llm.model,
                temperature=self.config.llm.temperature,
                dashscope_api_key=self.config.llm.api_key
            )
        else:
            raise ValueError(f"Unsupported LLM provider: {self.config.llm.provider}")

    async def run(self, message: str, thread_id: Optional[str] = None):
        """
        è¿è¡Œ Agentï¼Œæ”¯æŒäººå·¥ç¡®è®¤

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            thread_id: çº¿ç¨‹ IDï¼Œç”¨äºä¼šè¯æŒä¹…åŒ–
        """
        from langgraph.types import Command

        if thread_id is None:
            thread_id = str(uuid.uuid4())

        print(f"\n{'='*60}")
        print(f"Thread ID: {thread_id}")
        print(f"User: {message}")
        print(f"{'='*60}\n")

        # å‡†å¤‡è¾“å…¥ - ä½¿ç”¨å®Œæ•´çš„åˆå§‹çŠ¶æ€
        input_data = create_initial_state()
        input_data["messages"] = [HumanMessage(content=message)]

        # é…ç½®
        config = {
            "configurable": {"thread_id": thread_id},
            "recursion_limit": 100
        }

        # æ‰§è¡Œå¾ªç¯ï¼Œå¤„ç†å¯èƒ½çš„ interrupt
        while True:
            # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨ ainvoke
            result = await self.app.ainvoke(input_data, config)
            final_message = result["messages"][-1]
            print(f"\nAssistant: {final_message.content}\n")

            # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­ï¼ˆéœ€è¦äººå·¥ç¡®è®¤ï¼‰
            state = await self.app.aget_state(config)

            # å¦‚æœæ²¡æœ‰ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¯´æ˜æ‰§è¡Œå®Œæˆ
            if not state.next:
                break

            # æ£€æŸ¥æ˜¯å¦æœ‰ interrupt å€¼
            if hasattr(state, 'tasks') and state.tasks:
                # æœ‰å¾…å¤„ç†çš„ä»»åŠ¡ï¼Œå¯èƒ½æ˜¯ interrupt
                interrupt_found = False
                for task in state.tasks:
                    if hasattr(task, 'interrupts') and task.interrupts:
                        # æ‰¾åˆ° interrupt ä¿¡æ¯
                        interrupt_data = task.interrupts[0].value
                        interrupt_found = True

                        # æ˜¾ç¤ºç¡®è®¤ä¿¡æ¯
                        print("\n" + "="*60)
                        # interrupt_data åŒ…å« "question" å­—æ®µï¼ˆæ¥è‡ª ask_human å·¥å…·ï¼‰
                        question = interrupt_data.get("question", interrupt_data.get("message", "Approval required"))
                        print(question)
                        print("="*60)

                        # è·å–ç”¨æˆ·è¾“å…¥
                        user_input = input("\nYour response: ").strip()

                        # ä½¿ç”¨ Command æ¢å¤æ‰§è¡Œ
                        input_data = Command(resume=user_input)
                        break

                if interrupt_found:
                    continue

            # æ²¡æœ‰æ‰¾åˆ° interruptï¼Œä½†è¿˜æœ‰ nextï¼Œå¯èƒ½æ˜¯å…¶ä»–æƒ…å†µï¼Œé€€å‡º
            break

    async def run_interactive(self):
        """äº¤äº’å¼è¿è¡Œ"""
        thread_id = str(uuid.uuid4())
        safe_print("\nğŸ¤– Claude Code Demo - Interactive Mode")
        safe_print("Type 'exit' to quit, 'new' to start a new conversation\n")

        while True:
            try:
                user_input = input("You: ").strip()

                if user_input.lower() == "exit":
                    print("Goodbye!")
                    break

                if user_input.lower() == "new":
                    thread_id = str(uuid.uuid4())
                    print(f"Started new conversation (thread: {thread_id})\n")
                    continue

                if not user_input:
                    continue

                await self.run(user_input, thread_id=thread_id)

            except KeyboardInterrupt:
                print("\nGoodbye!")
                break
            except Exception as e:
                print(f"\nâŒ Error: {e}\n")

    def visualize(self, output_path: str = "graph.png"):
        """
        å¯è§†åŒ–å›¾ç»“æ„

        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        png_data = visualize_graph(self.app)
        if png_data:
            with open(output_path, "wb") as f:
                f.write(png_data)
            safe_print(f"âœ… Graph visualization saved to {output_path}")
        else:
            safe_print("âŒ Failed to generate graph visualization")


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ§åˆ¶å°ç¼–ç 
    setup_console_encoding()

    # åˆ›å»ºé…ç½®
    config = get_default_config()

    # åˆ›å»ºåº”ç”¨
    app = ClaudeCodeDemo(config)

    # å¯è§†åŒ–å›¾ï¼ˆå¯é€‰ï¼‰
    app.visualize("claude_code_graph.png")

    # è¿è¡Œç¤ºä¾‹
    print("\n" + "="*60)
    print("Claude Code Demo - Example Usage")
    print("="*60 + "\n")

    # ç¤ºä¾‹ 1: ç®€å•é—®ç­”
    # await app.run("å¸®æˆ‘è®¡ç®— 123 + 456 ç­‰äºå¤šå°‘ï¼Ÿ")

    # ç¤ºä¾‹ 2: æ–‡ä»¶æ“ä½œï¼ˆéœ€è¦ç¡®è®¤ï¼‰
    # await app.run("è¯·å¸®æˆ‘åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ test.txtï¼Œå†…å®¹æ˜¯ 'Hello, Claude Code!'")

    # ç¤ºä¾‹ 3: å¤æ‚ä»»åŠ¡ï¼ˆä¼šä½¿ç”¨ TodoListï¼‰
    await app.run("å¸®æˆ‘åˆ†æä¸€ä¸‹å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰ Python æ–‡ä»¶ï¼Œæ‰¾å‡ºå¯èƒ½çš„ä»£ç è´¨é‡é—®é¢˜")

    # äº¤äº’å¼æ¨¡å¼
    # await app.run_interactive()


if __name__ == "__main__":
    asyncio.run(main())
